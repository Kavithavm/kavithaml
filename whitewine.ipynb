{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "facJdPebmKCh",
    "colab_type": "code",
    "outputId": "a853c65e-f4f7-426d-b54e-70a233e53294",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346703775E12,
     "user_tz": -330.0,
     "elapsed": 52489.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.chdir('/content/gdrive/My Drive/ML/wine dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nUCpBgNHmdG3",
    "colab_type": "code",
    "outputId": "d519edf0-cb35-48f6-df16-ee0c4640ad42",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346706484E12,
     "user_tz": -330.0,
     "elapsed": 55160.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redwine.csv  whitewine.csv  winequality-red.csv  winequality-white.csv\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "eZPsYpV1mdLU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('whitewine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Iku22gBqmdPq",
    "colab_type": "code",
    "outputId": "22f05125-b8b9-4bb3-dbf2-36d7b5250d0c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346717602E12,
     "user_tz": -330.0,
     "elapsed": 1443.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1986.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.033</td>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.99080</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.035</td>\n",
       "      <td>17.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.99470</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.040</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>48.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19.25</td>\n",
       "      <td>0.040</td>\n",
       "      <td>41.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.032</td>\n",
       "      <td>28.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99140</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.029</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.033</td>\n",
       "      <td>17.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>34.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.029</td>\n",
       "      <td>29.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.98920</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>19.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.049</td>\n",
       "      <td>41.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.074</td>\n",
       "      <td>25.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99370</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.052</td>\n",
       "      <td>16.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.046</td>\n",
       "      <td>56.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.052</td>\n",
       "      <td>35.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.39</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.051</td>\n",
       "      <td>32.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99610</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.047</td>\n",
       "      <td>17.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99140</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.033</td>\n",
       "      <td>37.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.046</td>\n",
       "      <td>42.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.99324</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10.10</td>\n",
       "      <td>0.032</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99626</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.021</td>\n",
       "      <td>29.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99188</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.015</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98970</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.55</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.032</td>\n",
       "      <td>50.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.030</td>\n",
       "      <td>33.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99044</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.048</td>\n",
       "      <td>16.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99282</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.035</td>\n",
       "      <td>18.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99245</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.038</td>\n",
       "      <td>34.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99132</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.032</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.99286</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.035</td>\n",
       "      <td>6.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99234</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4881</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>45.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.99184</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.035</td>\n",
       "      <td>60.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.98964</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>68.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99492</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.550000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.028</td>\n",
       "      <td>45.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99168</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.98928</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.052</td>\n",
       "      <td>38.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.99330</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.036</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.98938</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>38.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99074</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.032</td>\n",
       "      <td>29.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99298</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36           20.70      0.045   \n",
       "1               6.3             0.300         0.34            1.60      0.049   \n",
       "2               8.1             0.280         0.40            6.90      0.050   \n",
       "3               7.2             0.230         0.32            8.50      0.058   \n",
       "4               7.2             0.230         0.32            8.50      0.058   \n",
       "5               8.1             0.280         0.40            6.90      0.050   \n",
       "6               6.2             0.320         0.16            7.00      0.045   \n",
       "7               7.0             0.270         0.36           20.70      0.045   \n",
       "8               6.3             0.300         0.34            1.60      0.049   \n",
       "9               8.1             0.220         0.43            1.50      0.044   \n",
       "10              8.1             0.270         0.41            1.45      0.033   \n",
       "11              8.6             0.230         0.40            4.20      0.035   \n",
       "12              7.9             0.180         0.37            1.20      0.040   \n",
       "13              6.6             0.160         0.40            1.50      0.044   \n",
       "14              8.3             0.420         0.62           19.25      0.040   \n",
       "15              6.6             0.170         0.38            1.50      0.032   \n",
       "16              6.3             0.480         0.04            1.10      0.046   \n",
       "17              6.2             0.660         0.48            1.20      0.029   \n",
       "18              7.4             0.340         0.42            1.10      0.033   \n",
       "19              6.5             0.310         0.14            7.50      0.044   \n",
       "20              6.2             0.660         0.48            1.20      0.029   \n",
       "21              6.4             0.310         0.38            2.90      0.038   \n",
       "22              6.8             0.260         0.42            1.70      0.049   \n",
       "23              7.6             0.670         0.14            1.50      0.074   \n",
       "24              6.6             0.270         0.41            1.30      0.052   \n",
       "25              7.0             0.250         0.32            9.00      0.046   \n",
       "26              6.9             0.240         0.35            1.00      0.052   \n",
       "27              7.0             0.280         0.39            8.70      0.051   \n",
       "28              7.4             0.270         0.48            1.10      0.047   \n",
       "29              7.2             0.320         0.36            2.00      0.033   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4868            5.8             0.230         0.31            4.50      0.046   \n",
       "4869            6.6             0.240         0.33           10.10      0.032   \n",
       "4870            6.1             0.320         0.28            6.60      0.021   \n",
       "4871            5.0             0.200         0.40            1.90      0.015   \n",
       "4872            6.0             0.420         0.41           12.40      0.032   \n",
       "4873            5.7             0.210         0.32            1.60      0.030   \n",
       "4874            5.6             0.200         0.36            2.50      0.048   \n",
       "4875            7.4             0.220         0.26            1.20      0.035   \n",
       "4876            6.2             0.380         0.42            2.50      0.038   \n",
       "4877            5.9             0.540         0.00            0.80      0.032   \n",
       "4878            6.2             0.530         0.02            0.90      0.035   \n",
       "4879            6.6             0.340         0.40            8.10      0.046   \n",
       "4880            6.6             0.340         0.40            8.10      0.046   \n",
       "4881            5.0             0.235         0.27           11.75      0.030   \n",
       "4882            5.5             0.320         0.13            1.30      0.037   \n",
       "4883            4.9             0.470         0.17            1.90      0.035   \n",
       "4884            6.5             0.330         0.38            8.30      0.048   \n",
       "4885            6.6             0.340         0.40            8.10      0.046   \n",
       "4886            6.2             0.210         0.28            5.70      0.028   \n",
       "4887            6.2             0.410         0.22            1.90      0.023   \n",
       "4888            6.8             0.220         0.36            1.20      0.052   \n",
       "4889            4.9             0.235         0.27           11.75      0.030   \n",
       "4890            6.1             0.340         0.29            2.20      0.036   \n",
       "4891            5.7             0.210         0.32            0.90      0.038   \n",
       "4892            6.5             0.230         0.38            1.30      0.032   \n",
       "4893            6.2             0.210         0.29            1.60      0.039   \n",
       "4894            6.6             0.320         0.36            8.00      0.047   \n",
       "4895            6.5             0.240         0.19            1.20      0.041   \n",
       "4896            5.5             0.290         0.30            1.10      0.022   \n",
       "4897            6.0             0.210         0.38            0.80      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "5                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "6                    30.0                 136.0  0.99490  3.18       0.47   \n",
       "7                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "8                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "9                    28.0                 129.0  0.99380  3.22       0.45   \n",
       "10                   11.0                  63.0  0.99080  2.99       0.56   \n",
       "11                   17.0                 109.0  0.99470  3.14       0.53   \n",
       "12                   16.0                  75.0  0.99200  3.18       0.63   \n",
       "13                   48.0                 143.0  0.99120  3.54       0.52   \n",
       "14                   41.0                 172.0  1.00020  2.98       0.67   \n",
       "15                   28.0                 112.0  0.99140  3.25       0.55   \n",
       "16                   30.0                  99.0  0.99280  3.24       0.36   \n",
       "17                   29.0                  75.0  0.98920  3.33       0.39   \n",
       "18                   17.0                 171.0  0.99170  3.12       0.53   \n",
       "19                   34.0                 133.0  0.99550  3.22       0.50   \n",
       "20                   29.0                  75.0  0.98920  3.33       0.39   \n",
       "21                   19.0                 102.0  0.99120  3.17       0.35   \n",
       "22                   41.0                 122.0  0.99300  3.47       0.48   \n",
       "23                   25.0                 168.0  0.99370  3.05       0.51   \n",
       "24                   16.0                 142.0  0.99510  3.42       0.47   \n",
       "25                   56.0                 245.0  0.99550  3.25       0.50   \n",
       "26                   35.0                 146.0  0.99300  3.45       0.44   \n",
       "27                   32.0                 141.0  0.99610  3.38       0.53   \n",
       "28                   17.0                 132.0  0.99140  3.19       0.49   \n",
       "29                   37.0                 114.0  0.99060  3.10       0.71   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4868                 42.0                 124.0  0.99324  3.31       0.64   \n",
       "4869                  8.0                  81.0  0.99626  3.19       0.51   \n",
       "4870                 29.0                 132.0  0.99188  3.15       0.36   \n",
       "4871                 20.0                  98.0  0.98970  3.37       0.55   \n",
       "4872                 50.0                 179.0  0.99622  3.14       0.60   \n",
       "4873                 33.0                 122.0  0.99044  3.33       0.52   \n",
       "4874                 16.0                 125.0  0.99282  3.49       0.49   \n",
       "4875                 18.0                  97.0  0.99245  3.12       0.41   \n",
       "4876                 34.0                 117.0  0.99132  3.36       0.59   \n",
       "4877                 12.0                  82.0  0.99286  3.25       0.36   \n",
       "4878                  6.0                  81.0  0.99234  3.24       0.35   \n",
       "4879                 68.0                 170.0  0.99494  3.15       0.50   \n",
       "4880                 68.0                 170.0  0.99494  3.15       0.50   \n",
       "4881                 34.0                 118.0  0.99540  3.07       0.50   \n",
       "4882                 45.0                 156.0  0.99184  3.26       0.38   \n",
       "4883                 60.0                 148.0  0.98964  3.27       0.35   \n",
       "4884                 68.0                 174.0  0.99492  3.14       0.50   \n",
       "4885                 68.0                 170.0  0.99494  3.15       0.50   \n",
       "4886                 45.0                 121.0  0.99168  3.21       1.08   \n",
       "4887                  5.0                  56.0  0.98928  3.04       0.79   \n",
       "4888                 38.0                 127.0  0.99330  3.04       0.54   \n",
       "4889                 34.0                 118.0  0.99540  3.07       0.50   \n",
       "4890                 25.0                 100.0  0.98938  3.06       0.44   \n",
       "4891                 38.0                 121.0  0.99074  3.24       0.46   \n",
       "4892                 29.0                 112.0  0.99298  3.29       0.54   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "        alcohol  quality  \n",
       "0      8.800000        6  \n",
       "1      9.500000        6  \n",
       "2     10.100000        6  \n",
       "3      9.900000        6  \n",
       "4      9.900000        6  \n",
       "5     10.100000        6  \n",
       "6      9.600000        6  \n",
       "7      8.800000        6  \n",
       "8      9.500000        6  \n",
       "9     11.000000        6  \n",
       "10    12.000000        5  \n",
       "11     9.700000        5  \n",
       "12    10.800000        5  \n",
       "13    12.400000        7  \n",
       "14     9.700000        5  \n",
       "15    11.400000        7  \n",
       "16     9.600000        6  \n",
       "17    12.800000        8  \n",
       "18    11.300000        6  \n",
       "19     9.500000        5  \n",
       "20    12.800000        8  \n",
       "21    11.000000        7  \n",
       "22    10.500000        8  \n",
       "23     9.300000        5  \n",
       "24    10.000000        6  \n",
       "25    10.400000        6  \n",
       "26    10.000000        6  \n",
       "27    10.500000        6  \n",
       "28    11.600000        6  \n",
       "29    12.300000        7  \n",
       "...         ...      ...  \n",
       "4868  10.800000        6  \n",
       "4869   9.800000        6  \n",
       "4870  11.450000        7  \n",
       "4871  12.050000        6  \n",
       "4872   9.700000        5  \n",
       "4873  11.900000        6  \n",
       "4874  10.000000        6  \n",
       "4875   9.700000        6  \n",
       "4876  11.600000        7  \n",
       "4877   8.800000        5  \n",
       "4878   9.500000        4  \n",
       "4879   9.533333        6  \n",
       "4880   9.533333        6  \n",
       "4881   9.400000        6  \n",
       "4882  10.700000        5  \n",
       "4883  11.500000        6  \n",
       "4884   9.600000        5  \n",
       "4885   9.550000        6  \n",
       "4886  12.150000        7  \n",
       "4887  13.000000        7  \n",
       "4888   9.200000        5  \n",
       "4889   9.400000        6  \n",
       "4890  11.800000        6  \n",
       "4891  10.600000        6  \n",
       "4892   9.700000        5  \n",
       "4893  11.200000        6  \n",
       "4894   9.600000        5  \n",
       "4895   9.400000        6  \n",
       "4896  12.800000        7  \n",
       "4897  11.800000        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NvEv61qpmdTS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "train1=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9D8aJaYUmda3",
    "colab_type": "code",
    "outputId": "beecf764-0a4d-4f7d-9963-dbc7dc73b937",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346726354E12,
     "user_tz": -330.0,
     "elapsed": 1062.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PqNsklyJmdfW",
    "colab_type": "code",
    "outputId": "f02aac82-a4de-42c4-9035-5cff30b60a98",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346731312E12,
     "user_tz": -330.0,
     "elapsed": 882.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           4898 non-null float64\n",
      "volatile acidity        4898 non-null float64\n",
      "citric acid             4898 non-null float64\n",
      "residual sugar          4898 non-null float64\n",
      "chlorides               4898 non-null float64\n",
      "free sulfur dioxide     4898 non-null float64\n",
      "total sulfur dioxide    4898 non-null float64\n",
      "density                 4898 non-null float64\n",
      "pH                      4898 non-null float64\n",
      "sulphates               4898 non-null float64\n",
      "alcohol                 4898 non-null float64\n",
      "quality                 4898 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eldFrfGimdji",
    "colab_type": "code",
    "outputId": "790e59ef-9934-4ca3-f9e8-275748d38297",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346736003E12,
     "user_tz": -330.0,
     "elapsed": 932.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity             6.80000\n",
       "volatile acidity          0.26000\n",
       "citric acid               0.32000\n",
       "residual sugar            5.20000\n",
       "chlorides                 0.04300\n",
       "free sulfur dioxide      34.00000\n",
       "total sulfur dioxide    134.00000\n",
       "density                   0.99374\n",
       "pH                        3.18000\n",
       "sulphates                 0.47000\n",
       "alcohol                  10.40000\n",
       "quality                   6.00000\n",
       "Name: 0.5, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#range\n",
    "train.quantile(.75-.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VB4JsRranFPL",
    "colab_type": "code",
    "outputId": "5ef3b50d-72bc-4abc-c4ee-3bfaf4bfce1c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346737047E12,
     "user_tz": -330.0,
     "elapsed": 558.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity            0.843868\n",
       "volatile acidity         0.100795\n",
       "citric acid              0.121020\n",
       "residual sugar           5.072058\n",
       "chlorides                0.021848\n",
       "free sulfur dioxide     17.007137\n",
       "total sulfur dioxide    42.498065\n",
       "density                  0.002991\n",
       "pH                       0.151001\n",
       "sulphates                0.114126\n",
       "alcohol                  1.230621\n",
       "quality                  0.885639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HZeHRSYnnFSw",
    "colab_type": "code",
    "outputId": "a151e997-3e2a-41e5-f382-9f5c0770bd71",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346741933E12,
     "user_tz": -330.0,
     "elapsed": 981.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity            2.172178\n",
       "volatile acidity         5.091626\n",
       "citric acid              6.174901\n",
       "residual sugar           3.469820\n",
       "chlorides               37.564600\n",
       "free sulfur dioxide     11.466342\n",
       "total sulfur dioxide     0.571853\n",
       "density                  9.793807\n",
       "pH                       0.530775\n",
       "sulphates                1.590930\n",
       "alcohol                 -0.698425\n",
       "quality                  0.216526\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lz8AQICrnFXI",
    "colab_type": "code",
    "outputId": "e4e6f7fb-76d5-4dcb-8b9e-9e4b6d9a08c2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346746026E12,
     "user_tz": -330.0,
     "elapsed": 945.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0.647751\n",
       "volatile acidity        1.576980\n",
       "citric acid             1.281920\n",
       "residual sugar          1.077094\n",
       "chlorides               5.023331\n",
       "free sulfur dioxide     1.406745\n",
       "total sulfur dioxide    0.390710\n",
       "density                 0.977773\n",
       "pH                      0.457783\n",
       "sulphates               0.977194\n",
       "alcohol                 0.487342\n",
       "quality                 0.155796\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iJY-omhxnFaB",
    "colab_type": "code",
    "outputId": "1aa73a27-0e99-4cad-fe8a-6f46704b21a2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346747442E12,
     "user_tz": -330.0,
     "elapsed": 1165.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity              0.712114\n",
       "volatile acidity           0.010160\n",
       "citric acid                0.014646\n",
       "residual sugar            25.725770\n",
       "chlorides                  0.000477\n",
       "free sulfur dioxide      289.242720\n",
       "total sulfur dioxide    1806.085491\n",
       "density                    0.000009\n",
       "pH                         0.022801\n",
       "sulphates                  0.013025\n",
       "alcohol                    1.514427\n",
       "quality                    0.784356\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zu8e5xpPnFdT",
    "colab_type": "code",
    "outputId": "6fa6bbae-5e98-4014-d748-6df4b711fe12",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346754302E12,
     "user_tz": -330.0,
     "elapsed": 3103.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9a2c05390>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFKCAYAAADmCN3IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9a2be76a0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "train.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZDKRnulbnFkd",
    "colab_type": "code",
    "outputId": "f991557e-c5f8-4f98-c033-bed38fc32b91",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54434675996E12,
     "user_tz": -330.0,
     "elapsed": 2582.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a2c20470>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a02d01d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a02884e0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a023f710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a01f5780>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a01f57b8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a015f550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a011a630>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a0150710>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a00e6dd8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a00bf160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa9a00766a0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFZCAYAAACIfRb+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/ZDFu9MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9a2bb56d8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1lFaTilcnFid",
    "colab_type": "code",
    "outputId": "da037ecc-ed5a-4dba-d7ef-f946998d13ca",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346768229E12,
     "user_tz": -330.0,
     "elapsed": 1635.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9a00543c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xt8z/X///H7eyezmcO0KUTyKXzQ\n2McplTKUzr6VMLb5NPIpolK2nPpYJypySEhh5pAcQp/6mIoiacWcKSwthu09drDNzLb3749+e382\ndnjjPZ5xu14uLhd7vV/v5+vxer+er9f99Xq+Xu/NYrPZbAIAAFeUy5UuAAAAEMgAABiBQAYAwAAE\nMgAABiCQAQAwAIEMAIAB3K7kwq3WU05rq1YtL6Wl5TitPWegJsdQk+NMrIuaHENNjjOxLmfV5Ofn\nU+ZrV80Vspub65Uu4TzU5BhqcpyJdVGTY6jJcSbWdTlqumoCGQCAvzICGQAAAxDIAAAYgEAGAMAA\nBDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwA\ngAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAAC\nGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAM4FAg5+bmqmvXrlqxYoWOHTumkJAQ\nBQcHa9iwYcrLy5MkrV69Wo8//rh69uyppUuXVmrRAABcbRwK5BkzZqhGjRqSpKlTpyo4OFiLFi1S\nw4YNtWzZMuXk5Gj69OmaN2+eYmJiFB0drfT09EotHACAq0mFgZyQkKCDBw/qnnvukSTFxcWpS5cu\nkqTOnTtr8+bN2rFjh1q2bCkfHx95enoqMDBQ8fHxlVo4AABXkwoDecKECYqMjLT/fPr0aXl4eEiS\nateuLavVqtTUVPn6+trn8fX1ldVqrYRyAQC4OrmV9+LKlSvVqlUr3XjjjaW+brPZLmj6uWrV8pKb\nm6tD8zrCz8/HaW05CzU5hpocZ2Jd1OQYanKciXVVdk3lBvK3336rw4cP69tvv9Xx48fl4eEhLy8v\n5ebmytPTU8nJyfL395e/v79SU1Pt70tJSVGrVq0qXHhaWs6lr8H/5+fnI6v1lNPacwZqcgw1Oc7E\nuqjJMdTkOBPrclZN5YV6uYE8efJk+/+nTZumevXqadu2bYqNjdWjjz6qtWvX6q677lJAQIBGjx6t\nzMxMubq6Kj4+XiNHjrzkwgEAuFaUG8ilee655xQREaElS5aobt266tGjh9zd3TV8+HCFh4fLYrFo\n8ODB8vExb7gBAABTORzIzz33nP3/c+fOPe/17t27q3v37s6pCgCAawy/qQsAAAMQyAAAGIBABgDA\nAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEM\nAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAA\nAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYA\nwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACB\nDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADCAW0UznD59WpGRkTpx4oTO\nnDmjZ599Vk2bNtWIESNUUFAgPz8/vfPOO/Lw8NDq1asVHR0tFxcXPfnkk+rZs+flWAcAAP7yKgzk\n9evXq0WLFho4cKCSkpL01FNPKTAwUMHBwbr//vs1adIkLVu2TD169ND06dO1bNkyubu764knnlC3\nbt1Us2bNy7EeAAD8pVU4ZP3AAw9o4MCBkqRjx46pTp06iouLU5cuXSRJnTt31ubNm7Vjxw61bNlS\nPj4+8vT0VGBgoOLj4yu3egAArhIVXiEX6d27t44fP66ZM2fqn//8pzw8PCRJtWvXltVqVWpqqnx9\nfe3z+/r6ymq1Or9iAACuQg4H8ieffKJ9+/bp5Zdfls1ms08v/v/iyppeXK1aXnJzc3W0hAr5+fk4\nrS1noSbHUJPjTKyLmhxDTY4zsa7KrqnCQN69e7dq166tG264Qc2aNVNBQYG8vb2Vm5srT09PJScn\ny9/fX/7+/kpNTbW/LyUlRa1atSq37bS0nEtfg//Pz89HVuspp7XnDNTkGGpynIl1UZNjqMlxJtbl\nrJrKC/UK7yFv2bJFc+bMkSSlpqYqJydHHTt2VGxsrCRp7dq1uuuuuxQQEKBdu3YpMzNT2dnZio+P\nV5s2bS65eAAArgUVXiH37t1bo0aNUnBwsHJzczV27Fi1aNFCERERWrJkierWrasePXrI3d1dw4cP\nV3h4uCwWiwYPHiwfH/OGHAAAMFGFgezp6amJEyeeN33u3LnnTevevbu6d+/unMoAALiG8Ju6AAAw\nAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCAD\nAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiA\nQAYAwABuV7oAAH8dnTq11y+/7KtwvqZNm2nDhrjLUBFw9SCQATistJB9avw6zYkMugLVAFcXhqwB\nADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxA\nIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAA\nGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgADdHZnr77be1detW5efna9CgQWrZsqVG\njBihgoIC+fn56Z133pGHh4dWr16t6Ohoubi46Mknn1TPnj0ru34AAK4KFQbyjz/+qAMHDmjJkiVK\nS0vT//3f/+n2229XcHCw7r//fk2aNEnLli1Tjx49NH36dC1btkzu7u564okn1K1bN9WsWfNyrAcA\nAH9pFQ5Zt23bVlOmTJEkVa9eXadPn1ZcXJy6dOkiSercubM2b96sHTt2qGXLlvLx8ZGnp6cCAwMV\nHx9fudUDAHCVqDCQXV1d5eXlJUlatmyZOnXqpNOnT8vDw0OSVLt2bVmtVqWmpsrX19f+Pl9fX1mt\n1koqGwCAq4tD95Al6euvv9ayZcs0Z84c3XvvvfbpNput1PnLml5crVpecnNzdbSECvn5+TitLWeh\nJsdQk+NMrIuaHENNjjOxrsquyaFA3rhxo2bOnKmPPvpIPj4+8vLyUm5urjw9PZWcnCx/f3/5+/sr\nNTXV/p6UlBS1atWq3HbT0nIurfpi/Px8ZLWeclp7zkBNjqEmx5lal2k1mfg5UZPjTKzLWTWVF+oV\nDlmfOnVKb7/9tmbNmmV/QKtjx46KjY2VJK1du1Z33XWXAgICtGvXLmVmZio7O1vx8fFq06bNJRcP\nAMC1oMIr5C+//FJpaWl6/vnn7dPGjx+v0aNHa8mSJapbt6569Oghd3d3DR8+XOHh4bJYLBo8eLB8\nfMwbcgAAwEQVBnKvXr3Uq1ev86bPnTv3vGndu3dX9+7dnVMZAADXEH5TFwAABiCQAQAwAIEMAIAB\nCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkA\nAAMQyAAAGKDCv4cM4Nr13OQNys7Nr3C+p8avK/d1b083TXu+k7PKAq5KBDKAMmXn5mtOZFC58/j5\n+chqPVXuPBUFNgCGrAEAMAKBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJAB\nADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIAB3K50AQDM\nFf7Hau0fML/cefY70o5HTUlBTqkJuFoRyADK9HGDRzQnsvwg9fPzkdV6qtx5xo9fpzucWRhwFWLI\nGgAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDA\nAAQyAAAGIJABADAAgQwAgAH484sAyvXU+HWX3Ia3J4caoCLsJQDKVNHfQpb+DGxH5gNQPoeGrPfv\n36+uXbtqwYIFkqRjx44pJCREwcHBGjZsmPLy8iRJq1ev1uOPP66ePXtq6dKllVc1AABXmQoDOScn\nR6+99ppuv/12+7SpU6cqODhYixYtUsOGDbVs2TLl5ORo+vTpmjdvnmJiYhQdHa309PRKLR4AgKtF\nhYHs4eGh2bNny9/f3z4tLi5OXbp0kSR17txZmzdv1o4dO9SyZUv5+PjI09NTgYGBio+Pr7zKAQC4\nilR4D9nNzU1ubiVnO336tDw8PCRJtWvXltVqVWpqqnx9fe3z+Pr6ymq1ltt2rVpecnNzvZi6S+Xn\n5+O0tpyFmhxDTY4zsS5qcgw1Oc7Euiq7pkt+qMtms13Q9OLS0nIudfF2fn4+slpPOa09Z6Amx1CT\n40yty7SaTPycqMlxJtblrJrKC/WL+h6yl5eXcnNzJUnJycny9/eXv7+/UlNT7fOkpKSUGOYGAABl\nu6hA7tixo2JjYyVJa9eu1V133aWAgADt2rVLmZmZys7OVnx8vNq0aePUYgEAuFpVOGS9e/duTZgw\nQUlJSXJzc1NsbKzeffddRUZGasmSJapbt6569Oghd3d3DR8+XOHh4bJYLBo8eLB8fMy7BwAAgIkq\nDOQWLVooJibmvOlz5849b1r37t3VvXt351QGAMA1hN9lDQCAAQhkAAAMQCADAGAAAhkAAAMQyAAA\nGIBABgDAAAQyAAAGuOTfZQ2gcnTq1F6//LKv3HmaNm2mDRviLlNFACoTgQwYqrSgfWr8Os2JDLoC\n1QCobAxZAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAA\nAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGMDtShcAQHpu\n8gZl5+Y7NO9T49eV+7q3p5umPd/JGWUBuIwIZMAA2bn5mhMZVOF8fn4+slpPlTtPRYENwEwMWQMA\nYAACGQAAAxDIAAAYgEAGAMAABDIAAAbgKWvAAOF/rNb+AfMrnG+/I2151JRU8RPbAMxCIAMG+LjB\nI0772tP48et0h7MKA3DZMGQNAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgKesAUM4649CeHuyWwN/\nRey5uOw6dWqvX37ZV+48TZs204YNcZepoivPka88SX+GtqPzVoaytp3/pJI/X2vbD3AGAhmX3bkH\n6isdMnBcaSHryHejAVSMe8gAABiAQAYAwAAMWQMArhieKfkfAhkAcMWUFrTX6nMlBDIA4LJ4bvIG\nZefmOzRvRV8D9PZ007TnOzmjLGMQyKhUju6AjnwH92rcAYFrSe/9K+SXl+6Utk5UqSnp6joe/CUD\nmXsOfx3ZufkVDj05+rUZZ/3iDABXxh0fTD5vGsfz/zE+kDc9+/x5Z1Qf3dpMurVZhe/dP6B/iZ+t\nHjVL7RAAgCvDxO+2O3KSIDn/RMHpgfzmm29qx44dslgsGjlypG677bZLas+ZZ1S3XlIluBjhf6zW\n/gHzy51nv6NtedSUdO096AGgcp174efoRZ9U8sLvUi/6nBrIP/30kxITE7VkyRIlJCRo5MiRWrJk\niTMXIcnMMyqU7uMGjzhtyHr8+HW6w1mFAU5U2kjeuRw98WQk7/I79/O+2CvkS73oc2ogb968WV27\ndpUkNW7cWBkZGcrKylK1atWcuRj8xfBHEy6OI783+lq5t2Y6RwLU0RNPRvKuvCt10efUI1xqaqqa\nN29u/9nX11dWq7XMQK5Vy0tubq5OW76fn4/T2qrIyp7hTjkjtnrUVI+lH1+1NX0+8dHzprVo0UJ7\n9uwp933NmzfX7t27nVLDuZz1OUnO/azOtW/f3kpptzJc6/ueo/6Kn5N09X9Wjqrsmiw2m83mrMbG\njBmju+++236V3KdPH7355ptq1KhRqfM782zDxCFranIMNTnOxLqoyTHU5DgT63JWTeWFulN/l7W/\nv79SU1PtP6ekpMjPz8+ZiwAA4Krk1EC+4447FBsbK0nas2eP/P39uX8MAIADnHoPOTAwUM2bN1fv\n3r1lsVj06quvOrN5AACuWk5/bPWll15ydpMAAFz1+HvIAAAYgEAGAMAABDIAAAYgkAEAMACBDACA\nAQhkAAAMQCADAGAAAhkAAAM49Y9LAACAi8MVMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAA\nA1RqIJ89e1Y9e/ZURESEVqxYoa+++uqi21q/fr0iIyMv+v0vvPCCcnNzS23TarVq7NixCgoK0saN\nG3XixIlS21izZo0kad++fZo6daokqX379hdd08XU+vnnnys4OFiSNH369FJrfeaZZ5xaT1nbrn37\n9uW+dqFCQkK0f//+i6qxNHFxcRo6dOgFLad4n5WkN954Q4cPHy4xz/79+xUSEuK0Os+t6+TJk3rw\nwQc1ceJE+2uxsbHlvvebb75RXl5eiWmPPfaYjhw5og8//FADBw7U+vXrHa6leB88cuSIHnvsMa1f\nv159+/bVfffdpy1btlzAmpVU/PNztK9mZ2crKCioxL5X3NChQxUXF1dhO0XbMysrS99///2FFX6J\nIiMjz9sGlXH8CAoKUnZ2dpmvX8gyS+tXF6uiukpzIbVWxmdZmqL1+PDDD7Vt2zZJFe+fjqrUQLZa\nrcrLy9OECRP02GOPqVu3bpW5uHK999578vT0LPU1Pz8/RUVFSZJWrVpVZiB/+OGHkqRmzZqVeqB3\nlvJqffjhh7Vo0SJJ0vz580utdcaMGU6tp7xtd6W3q7MV77OSNGrUKN14442XtYaEhAQ1bNhQw4cP\nl/RnIH7xxRflvmfevHk6e/Zsqa89/fTTql279gXVUFYfTElJ0csvv6w2bdpcUHtludC+eqn7XtH2\n3LNnjzZt2nTR7VwryutX17qnn35arVu3dmj/dJSbU1opw1tvvaU//vhDr7zyiurWratatWqpWrVq\n2rlzp8aOHatVq1Zp69atioqK0nvvvactW7aooKBA/fr100MPPaRff/1VERERqlGjhho0aHBe+1lZ\nWRo+fLhycnKUm5urMWPG6LbbbtOmTZs0adIkubq66vjx4/rkk0/Ur18/zZo1S8OGDZO7u7s9yPLz\n87Vy5UrNnz9fubm5Wr9+vfbu3aucnBxZLBY1aNBAU6ZM0ZNPPqkjR45oyJAhCgkJ0cKFC0ucqR88\neFBRUVGyWCzy9vbW+PHjVb169Quq9YEHHlD//v0VFBSkzz//XL///rv69++vwsJCeXl5KTAwUB99\n9JHmzJmjoKAgpaenq2/fvurSpYvi4+NVp04dRUREqFevXlq+fLkKCws1btw4WSwWtW7d2n7VV2TO\nnDmKjY1VYWGh/P395e7urmPHjsnT01NJSUnKyMjQzTffLG9vbwUFBSkgIEDh4eHKz89X9erVVVhY\nqGnTpqlWrVrq3bu3hg8fruPHj6tly5b2ZYSEhGjMmDG69dZbtWDBAqWlpemZZ55RRESEkpOTlZOT\no+eee06dO3cutQ+tXLlSCxYskLu7u5o2bapXX3211Db/9a9/afjw4YqLi5OHh4fS09P1xhtvKCkp\nSR06dFBubq6uv/56rV69WpmZmRo3bpwKCwvl5uZm7wejR4/WzJkz9euvvyooKEi33nqrdu7cqTp1\n6uj9999Xnz59lJOTI09PT/u2Xbp0qT28fXx8tHDhQknSyy+/LBcXF+Xl5cnNzc3+/7FjxyorK6tE\n/2nfvn2Jq7u33npLR48e1cSJE2W1WnXgwAElJSXppZdeks1mU1pamnbs2CEXFxcNGTJENWrU0Pbt\n2zVw4EA1adLEvk1zcnL0xRdf6NChQzp27Jjy8/P1yiuv6PDhw8rLy1NQUJBiY2N16NAh3XnnnYqK\nitK9996rcePGaeLEiXr55Ze1evVqJSYm6vjx41q0aJGSk5M1ZcoUxcXFaeHChWrVqpW6du2q7du3\nq2/fvvrpp590+PBhHTlyRDExMXJ1dZUkHT9+XMOGDZOHh4eaNGliX9eidf/1118VFRUlFxcX+/6z\nZs0azZgxQ/Xq1VP16tWVlpam+fPna/r06WrSpIlOnTpl3zcOHTqktLQ0jRs3TtKfJ9nJyclyc3OT\nj4/PeX0nKipKWVlZ8vX11bJly7RmzRpZLBatXr1ae/bs0SuvvFL2gc0BK1as0MaNG5WVlaXjx4+r\nf//+l9SeJB09etTerwoKCtSxY0dlZ2crIiJC2dnZevjhh7Vu3Tr7/JGRkfLy8tJvv/2mtLQ0vfXW\nW/r73/8uSZoyZYo2bdqkmjVraubMmfYTLenPfWHChAmKj4+396t58+Zp6dKl+vzzz+Xi4qKuXbvq\nqaee0t69ezVu3Dh5eHjIw8ND7733nqpXr17q8a5IUlKSIiMjVVBQoLp162rChAmyWq0aOXKkzp49\nK4vFojfeeMN+InxurdnZ2YqMjFRmZqZ9v23evLnDn2NWVpaGDBmiM2fOqEOHDlq1apUk6fPPP5e3\nt7cmTJigW265Rffee2+px+zin+99992nxYsXa+fOnXr//fe1cuVKrVq1St7e3tq6davmzp2r999/\n3+HaKvUKOSIiQo0aNdJbb71ln9ajRw8dOnRIe/bsUXR0tF566SVt2bJFSUlJWrhwoebPn68ZM2Yo\nNzdXH3zwgYYMGaLo6Gi5uJxfqtVqVc+ePRUTE6MXX3xRs2fPls1m07hx4zR79mwtXrxYVatW1dq1\nayVJ3333nVxcXNSuXTt16dJFXbp0Ufv27e0HRk9PTzVp0kRhYWGaMGGCqlWrpsDAQC1dulTe3t7y\n8fEp88N97bXXFBUVpejoaN1xxx32A/OF1Lp58+YSQ9VjxoxRmzZttHXrVjVu3FjHjh2zv/b666/L\nzc1NCxcuVLdu3ZSUlKSPP/5YDRs2lM1mU9OmTfX6669r3Lhx+uSTT3TixAklJSWdV/eiRYv06aef\nasuWLTpy5Ijat2+vf/zjH7rhhhv07LPPasCAAUpISFBGRoY++OAD1a9fX/Hx8Ro4cKAyMzPt7Wza\ntEn5+flasmSJHn74YaWnp5fZLzIyMnTnnXdqwYIFmjJliqZNm1bmvB9//LGmTZumxYsXq0WLFucN\n5RfZuHGjEhMT1aNHD0VFRSkvL09ZWVn2YNi0aZOSkpLsw5SJiYnq0KGD7rrrLsXExGjkyJF66623\nFBERIZvNplmzZql58+ay2WyaMGGCJk6cqOuuu05btmxRcHCwjh49qhMnTujdd9/VxIkTtWXLFt1w\nww2KiopSbGysOnbsqJiYGN17773y8fFRTEyM3n333TJHX4qLiIhQu3bt7FfI3bp1U7t27fTggw8q\nISFBzZo1U0FBgaZMmaKvvvpKPXr0kJ+fn1555RVt27ZNgwYN0meffaaCggJFR0fb292yZYs8PDy0\nYMECTZs2TTNnztSoUaM0duxYWSwWTZ48WU2aNJGXl5f9Pb/88ovCwsJ00003qW7duqpTp45CQ0P1\nyy+/2E9A1q5dq9OnT9vfc/bsWS1atMgextKfozkPPPCAYmJi5O/vf946v/HGGxoxYoRiYmLUtm1b\nzZ8/XwUFBbJYLBo1apQOHDigGjVqKCYmRq1bt9b777+vP/74Q2FhYRo0aJAyMjI0cOBAdevWTceO\nHVN0dLRsNpuqV69eat8JDw/XAw88YD+JKRp6/Oabb/TQQw9VuI0ccfDgQc2YMUPR0dGaPHmyCgsL\nNWnSJIWEhNj/XYji/WrUqFHy8PCo8D35+fmaN2+ehg0bpunTp0v6c/+777779OmnnyojI0O//vqr\nUlJSNHjwYMXExOjxxx/XokWL7P1q9uzZSk5O1po1a7R48WL7Nj969KhWrFihPn36KCYmRgMGDJDV\napVU+vGuyHvvvaf+/ftr0aJF8vf31+7duzVlyhQ98cQTiomJUXBwsP04W1qt0dHRCggIKLHfXohV\nq1apWbNmWrx4sf72t7+VOV9561BceHi42rVrpyFDhqhbt272k6KL6UtX5KGu0aNHKzw8XKGhoape\nvbri4+O1Y8cOhYSEKDw8XIWFhbJarUpISFBgYKCk0u8PXHfddYqNjVWfPn307rvvKj09XSdPnlSV\nKlXk6+srV1dXvf/++9q4caMk6dtvv1VeXp5Onz6t9u3bq3379qpatao8PDyUn59vb7dmzZqaPXu2\nUlJS9Nlnn2nnzp3q3r17ueu0c+dOjRkzRiEhIVq9evV5B15Hap01a1aJYcIjR46oa9eukqQnn3xS\nN998c6nLrlatmmrWrKkDBw7ou+++k7u7uyTp0KFDatq0qSTp7bffVr169Uq8z9PTU/369VNoaKhy\ncnL0t7/9Tfv27VOVKlWUmJiodevWaf78+crLy1N6err8/Px09OhRTZ48WW3bti1R68GDB9W6dWtJ\nUkBAQJlD7pJUvXp17dq1S71791ZERES54f3QQw9p8ODBmjdvnu6+++4y201ISFCVKlUUGBiou+++\nW+7u7mrcuLFuvvlmvf766xo0aJDOnj1rX9ZNN92kffv22ftVy5YtlZiYKElycXHRLbfcIkny9vaW\n9OdzA6mpqQoJCdFXX30lm82mrVu3KjMzUy+++KLatGmjvXv3ymq16o477tCqVas0fvx4NWrUSH/8\n8YfGjh2rxMREderUqcx1dURaWppatWqlG2+8UR07drTXLEm//fabWrdurczMTL3wwgtyc3Mr8dkm\nJiba17dOnTqqUaOGRo8ereTkZJ08eVLHjh07b3j+1KlTatGihaT/7YO///67EhMTlZWVpdDQUGVn\nZ5cI5OJXEUUSEhLs/aO0fTnLHEkCAAAL7klEQVQhIUEBAQH21/fu3auEhAT1799f4eHh6t+/v06e\nPKnk5GRt375dYWFhslgsOnHihKpWrapatWqpSpUq2rNnj86cOaOQkBDl5+dr7969FfadRx99VF9+\n+aXy8vJ05MiREiM8l6Jt27Zyc3OTr6+vatSoobS0NL344ouKiYmx/7sQxftVXl6errvuugrf07Fj\nR0lSq1atdOjQIUl/Hi+Kjgt16tTRqVOn5Ofnp5iYGPXt21fR0dHn7ZO7du1SYmKiQkND7ds8KSlJ\nXbp00YwZMzR58mTVrl1bjRs3llT68a7I3r177cf1ESNGKCAgQLt371a7du0k/W/7l1Xr7t27S91v\nHVW8rxUtszTlrUNZivqSJP30009ljvyVpVKHrMuSlpYmb29vJScnS5I8PDz0xBNPaNCgQSXms9ls\nslgskqTCwsLz2omOjladOnX0zjvvaNeuXXr77bfl4uJSYt5bbrlFKSkpys/P16lTp+Tu7i6LxSKb\nzaaiX+N99uxZValSxf6e2bNna+jQocrLy9P8+fN16NAhRUREaM6cOWWuU9WqVTV//nx7vRdTa2mK\naqxovvr162vNmjU6evSo/cy5tFGFIklJSZo3b54+++wzeXt7q1OnTnJzc5Orq6tcXFx0zz332O+r\nFw1L5+bmKiwsTPXq1VNkZGSJkxibzVZieaXVWzT/f/7zH2VkZGjRokVKT0/XE088UWadgwYN0sMP\nP6zY2FiFhYVpwYIFpbZps9nk6uqqwsLCEttg3759Wr58uRo3blwiKIr3g3NrLv7+onWyWCzq2rWr\nxo4dq23btmnSpEmqX7++PD099d///ve8q75Vq1Zp06ZNmjt3rsLDw1WnTh0tXrxY27dvP+8gUPxz\nPFfxWoqva9FJV/HP2WazyWq1av/+/YqJidFDDz2k48ePl2iv+Pp6enpq5syZ+uGHH7R79241atRI\nvr6+ZdZVtCxXV1fdc889io2NtYdK8Yezimo7d7lFn2VFffns2bNycXGRzWZTTk6OvL29lZKSInd3\nd1WrVk0BAQEaMGCAPvjgAw0cOLDEcL+7u7u8vLzsdR09erTMvlOkU6dOmjJlin788ccLPoCW59xt\nU9axwVG33nqrvV9NmjRJjz32mP21svpQ8RqKll985KKotqlTp+rOO+9Unz59tGbNGn377bcl5nF3\ndy9xTChu2bJl9odOR4wYoQ4dOpR6vCvi6uqqc/+EQvF9sWj7l1VrWfuto4pvi3PbL1q+VPoxuyJN\nmzZVamqqdu7cqVtuuaVErjjisl8h5+fn691339XChQv1zTff6MiRI7rtttu0fv16FRYW6syZM3rt\ntdckSY0aNdLu3bslqdQnKNPS0uz3lr/++mudPXtWtWrVUkFBgZKTk2Wz2TRo0CDdfvvtyszM1D33\n3KNGjRrJx8dHcXFxiouLU05OjlxcXOwbxmKxKCMjQw0aNFCHDh20Z88e5ebmqn79+ud1ouKaNm2q\nDRs2SJK++OILbd68+aJqLT4MXL9+fftw+2effaZff/21RJs2m00FBQWS/rxn9vPPPyszM9PemRs3\nbqwdO3ZIkkaOHKmEhIQS9fj6+srb21t79uxRWlqaCgsL1aJFC2VkZCguLk7z58/XihUrtGHDBp09\ne1aJiYnasWOHHnnkEd19990lDgLFt1V8fLz9ycxq1arZh7Hi4+Pty65fv75cXFz01VdflfkUZ2Fh\nod577z35+fnpn//8p1q1aqWjR4+W2maDBg2Un5+vH3/8Ud9//73y8/O1bds25efn64YbblBmZqbO\nnj1b4gGVli1b2vvV9u3b7VfFpWnSpIk2bNigwsJCbdq0Sb///rsaNWokm81mvwc1YsQILViwQF98\n8YUOHDigrl27qkuXLvr666915513asyYMdq9e7eqVaumlJQUSX8OCZf35Km3t7f9XtnWrVtVq1Yt\nbd++/byaLRaL6tevr4MHD+r6669XSkqKDh8+rMLCQvsBq2HDhvb1PXbsmDIyMlSrVi1lZWWpQ4cO\nuvXWW5WYmGj/bLdv365q1arZn0gvem9ROxaLRTk5Ofr3v/9tv6IpS0X78i233GIfNv7555/VokUL\nNWzYUJ988okWLlyoNWvW2EcrsrKy1KBBA23fvl27du3S6dOn7ftNQECA8vLyVFhYqDFjxujLL78s\n0XeKuLi42Puvu7u72rZtq6lTp+rhhx8udz0uxPbt21VQUKCTJ08qOztbNWvWvKT2iverYcOGac6c\nOfZ+tHXr1lLfUzR927Zt9qvX0hQdn2w2m7755hv7fmKxWFRQUKDmzZsrLi5Op0+fls1m0+uvv67c\n3FwtWLBA6enpeuSRRxQWFqZ9+/aVaE/63/GuSIsWLfTjjz9K+vP+8A8//FBiXyza/mW5kP22NDff\nfLP9uFh0nC46phQUFNhfK28diivelyTp/vvvV1RU1EX1pcseyPPmzVPnzp11/fXX64UXXtBrr72m\nwMBAtW/fXr169VLfvn3tN+ifeeYZvfPOOxo4cGCpZ92PPvqo5s6dq6eeekq33XabrFarli9frldf\nfVVDhw5V7969dfvtt+uhhx7S6dOn1bVrVz3zzDPauHGjvvvuO3333Xf6+eef9cILL9jb/Mc//qGs\nrCwNHDhQL730klq2bKn09HT98ssvatasWZlXc6NGjdKsWbPUr18/rVixQs2aNbuoWos/CFZ0Ndau\nXTsdPHjwvAfbbrjhBvvDZi4uLmrcuHGJM/xRo0Zp/Pjx6tOnj2rUqFFih2zWrJm8vb3Vu3dvffnl\nl2rfvr1++OEHhYWFKSEhwX7WvGDBAnl5ecnd3V1BQUHasmWL2rRpo5UrV5YYMuvUqZNyc3PVr18/\nffnll6pTp44kqVevXoqKitLTTz9tv4q89957tW7dOoWFhalq1aq6/vrrS703X/SAT69evexDlM2a\nNSu1zc6dO6t69epau3atxowZI1dXV9WtW1c33nij+vTpozFjxsjT01OzZs2y71ihoaHas2ePQkND\nNXHiRI0aNarUbStJL730ks6cOaO2bdtq8eLF8vb2VtWqVTVq1CjNmDFDgYGB2rx5s+6++27ddNNN\nioqKUmhoqGJjY3X8+HGFhIRoxIgRGjBggJo2bSovLy/17t1bq1atOu9Wwrn9Zu3atfr+++/1888/\nq3Hjxtq/f79+//33EjW3a9dO//73v9W8eXN988036tmzp/z9/dWhQwd7gLdt21YFBQUKCQnRCy+8\noJ49e6pv376aOXOmPDw8NGrUKJ08eVKzZs1Samqq3Nzc1LRpU3344YdKTEy074O+vr4KDQ2Vm5ub\nbr/9dm3durXcA2jRZ718+XKFh4crIyPjvNdHjx6tSZMmKTQ0VLt27VJoaKiysrLk7u6uiIgItW7d\nWhkZGQoPD9fu3bv17LPP6rrrrtOYMWP00Ucf2febfv36qbCwUP369dPGjRu1fPnyEn2nyN///nf9\n97//1ccffyzpz4OoxWJRw4YNy12PC1GvXj0NGzZMYWFhev7558sdsXJE8X41ffp0vfPOOzp06JBC\nQkL022+/lXoFfubMGQ0aNEhTpkzR4MGDy2y7V69eeu211zRgwAA9+OCD+umnn/T999+rXbt2Cg4O\nlqenp0JDQ9W3b189+eST8vPzk6enpxo0aGBfx//85z/2ECrteFd0QTN06FB9+umn6tevn/25laFD\nh2rlypUKDQ3VihUryn2S/kL229I8+uij2rVrl/r27Wu/yOnXr5/+9a9/aciQIfb7ymUds8/VuHFj\n7d27V2+++aYk6YEHHtDx48fVoUOHC6pL4s8vluvMmTMKDg7WvHnz5OPjc6XLKddfqdbKkJ6erri4\nON13331KTk5WWFiY/XvjQEWmTp2qevXq6fHHH3dKeytWrNCBAwfO+2bD5VT0FLAzh+GvNqU9nX6p\nli9frqSkpIv6et4VuYf8V7B9+3aNHTtW4eHhxgfcX6nWyuLt7W2/4iksLLzkr63g2vH000/L09Oz\n3CtIwBGjR4/W4cOH7U+0XyiukAEAMAC/yxoAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAH+\nH2iw7BoGQ6A9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9a02d0da0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4KrVJXIznkJL",
    "colab_type": "code",
    "outputId": "d73e60b6-d2ad-4c0b-8e9a-8015ec5dfac9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544346774575E12,
     "user_tz": -330.0,
     "elapsed": 872.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022697</td>\n",
       "      <td>0.289181</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>-0.049396</td>\n",
       "      <td>0.091070</td>\n",
       "      <td>0.265331</td>\n",
       "      <td>-0.425858</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>-0.120881</td>\n",
       "      <td>-0.113663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>-0.022697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.149472</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.070512</td>\n",
       "      <td>-0.097012</td>\n",
       "      <td>0.089261</td>\n",
       "      <td>0.027114</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>-0.035728</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>-0.194723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>0.289181</td>\n",
       "      <td>-0.149472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094212</td>\n",
       "      <td>0.114364</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.121131</td>\n",
       "      <td>0.149503</td>\n",
       "      <td>-0.163748</td>\n",
       "      <td>0.062331</td>\n",
       "      <td>-0.075729</td>\n",
       "      <td>-0.009209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.094212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088685</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.401439</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>-0.194133</td>\n",
       "      <td>-0.026664</td>\n",
       "      <td>-0.450631</td>\n",
       "      <td>-0.097577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.023086</td>\n",
       "      <td>0.070512</td>\n",
       "      <td>0.114364</td>\n",
       "      <td>0.088685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>0.198910</td>\n",
       "      <td>0.257211</td>\n",
       "      <td>-0.090439</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>-0.360189</td>\n",
       "      <td>-0.209934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>-0.049396</td>\n",
       "      <td>-0.097012</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>0.299098</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615501</td>\n",
       "      <td>0.294210</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>0.059217</td>\n",
       "      <td>-0.250104</td>\n",
       "      <td>0.008158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>0.091070</td>\n",
       "      <td>0.089261</td>\n",
       "      <td>0.121131</td>\n",
       "      <td>0.401439</td>\n",
       "      <td>0.198910</td>\n",
       "      <td>0.615501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529881</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.134562</td>\n",
       "      <td>-0.448892</td>\n",
       "      <td>-0.174737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.265331</td>\n",
       "      <td>0.027114</td>\n",
       "      <td>0.149503</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.257211</td>\n",
       "      <td>0.294210</td>\n",
       "      <td>0.529881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093591</td>\n",
       "      <td>0.074493</td>\n",
       "      <td>-0.780138</td>\n",
       "      <td>-0.307123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>-0.425858</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>-0.163748</td>\n",
       "      <td>-0.194133</td>\n",
       "      <td>-0.090439</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>-0.093591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155951</td>\n",
       "      <td>0.121432</td>\n",
       "      <td>0.099427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>-0.017143</td>\n",
       "      <td>-0.035728</td>\n",
       "      <td>0.062331</td>\n",
       "      <td>-0.026664</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>0.059217</td>\n",
       "      <td>0.134562</td>\n",
       "      <td>0.074493</td>\n",
       "      <td>0.155951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>0.053678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>-0.120881</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>-0.075729</td>\n",
       "      <td>-0.450631</td>\n",
       "      <td>-0.360189</td>\n",
       "      <td>-0.250104</td>\n",
       "      <td>-0.448892</td>\n",
       "      <td>-0.780138</td>\n",
       "      <td>0.121432</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>-0.113663</td>\n",
       "      <td>-0.194723</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>-0.097577</td>\n",
       "      <td>-0.209934</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>-0.174737</td>\n",
       "      <td>-0.307123</td>\n",
       "      <td>0.099427</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.435575</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fixed acidity  volatile acidity  citric acid  \\\n",
       "fixed acidity              1.000000         -0.022697     0.289181   \n",
       "volatile acidity          -0.022697          1.000000    -0.149472   \n",
       "citric acid                0.289181         -0.149472     1.000000   \n",
       "residual sugar             0.089021          0.064286     0.094212   \n",
       "chlorides                  0.023086          0.070512     0.114364   \n",
       "free sulfur dioxide       -0.049396         -0.097012     0.094077   \n",
       "total sulfur dioxide       0.091070          0.089261     0.121131   \n",
       "density                    0.265331          0.027114     0.149503   \n",
       "pH                        -0.425858         -0.031915    -0.163748   \n",
       "sulphates                 -0.017143         -0.035728     0.062331   \n",
       "alcohol                   -0.120881          0.067718    -0.075729   \n",
       "quality                   -0.113663         -0.194723    -0.009209   \n",
       "\n",
       "                      residual sugar  chlorides  free sulfur dioxide  \\\n",
       "fixed acidity               0.089021   0.023086            -0.049396   \n",
       "volatile acidity            0.064286   0.070512            -0.097012   \n",
       "citric acid                 0.094212   0.114364             0.094077   \n",
       "residual sugar              1.000000   0.088685             0.299098   \n",
       "chlorides                   0.088685   1.000000             0.101392   \n",
       "free sulfur dioxide         0.299098   0.101392             1.000000   \n",
       "total sulfur dioxide        0.401439   0.198910             0.615501   \n",
       "density                     0.838966   0.257211             0.294210   \n",
       "pH                         -0.194133  -0.090439            -0.000618   \n",
       "sulphates                  -0.026664   0.016763             0.059217   \n",
       "alcohol                    -0.450631  -0.360189            -0.250104   \n",
       "quality                    -0.097577  -0.209934             0.008158   \n",
       "\n",
       "                      total sulfur dioxide   density        pH  sulphates  \\\n",
       "fixed acidity                     0.091070  0.265331 -0.425858  -0.017143   \n",
       "volatile acidity                  0.089261  0.027114 -0.031915  -0.035728   \n",
       "citric acid                       0.121131  0.149503 -0.163748   0.062331   \n",
       "residual sugar                    0.401439  0.838966 -0.194133  -0.026664   \n",
       "chlorides                         0.198910  0.257211 -0.090439   0.016763   \n",
       "free sulfur dioxide               0.615501  0.294210 -0.000618   0.059217   \n",
       "total sulfur dioxide              1.000000  0.529881  0.002321   0.134562   \n",
       "density                           0.529881  1.000000 -0.093591   0.074493   \n",
       "pH                                0.002321 -0.093591  1.000000   0.155951   \n",
       "sulphates                         0.134562  0.074493  0.155951   1.000000   \n",
       "alcohol                          -0.448892 -0.780138  0.121432  -0.017433   \n",
       "quality                          -0.174737 -0.307123  0.099427   0.053678   \n",
       "\n",
       "                       alcohol   quality  \n",
       "fixed acidity        -0.120881 -0.113663  \n",
       "volatile acidity      0.067718 -0.194723  \n",
       "citric acid          -0.075729 -0.009209  \n",
       "residual sugar       -0.450631 -0.097577  \n",
       "chlorides            -0.360189 -0.209934  \n",
       "free sulfur dioxide  -0.250104  0.008158  \n",
       "total sulfur dioxide -0.448892 -0.174737  \n",
       "density              -0.780138 -0.307123  \n",
       "pH                    0.121432  0.099427  \n",
       "sulphates            -0.017433  0.053678  \n",
       "alcohol               1.000000  0.435575  \n",
       "quality               0.435575  1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bivariate Analysis\n",
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nzdk3Iq4nkNH",
    "colab_type": "code",
    "outputId": "a7008205-579c-4962-a4bd-04b27b4c70ba",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54434678019E12,
     "user_tz": -330.0,
     "elapsed": 1442.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336.0
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAE/CAYAAADSYGBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XlclNX+wPHPDDIuIO6SG0VcDffl\nplaWqVEWapqJggKmpuZPRE27Iu5oqeWSS3rVXBAQraTULCiNromK5Q6aKJkJmGKCCi4MM8/vD65z\nnXAZlWcW/L5fr+eVzHOe8z3PSM53zjnPORpFURSEEEIIIf5La+sGCCGEEMK+SHIghBBCCDOSHAgh\nhBDCjCQHQgghhDAjyYEQQgghzEhyIIQQQggzZWzdgEfZO5onrB5zTv4xq8cE0O3bZPWYGu/nrB4T\nwFihik3i5hudbBK34vULNonL7wetHnJuXkOrxwQIaVvXJnH/umawSVyNxiZh8ajqqkq99/Nv/b+V\n31Vpw/2S5EAIIYRQkZONkp2HIcmBEEIIoSInW3WFPARJDoQQQggVSc+BEEIIIcw4Ys+BXT2toNfr\n8fPzY9y4ccTFxfH9998/cF2JiYmEhYU98PWjR4/m+vXrt60zOzubyZMnA/Dzzz/z119/PXAcIYQQ\npZtOq7H4sBd21XOQnZ1NQUEBs2fPtnVTmD9//h3P1ahRg4iICAA2btzIwIEDqVatmrWaJoQQwoHI\nsMJDmjlzJn/88Qfjx4+ndu3aVKlSBVdXVw4fPszkyZPZtGkT+/btIyIigvnz5/PLL79gMBgIDAyk\na9euHD9+nHHjxlGpUiU8PDyK1Z+Xl8eYMWO4evUq169fZ9KkSTRr1oykpCTmzZuHk5MTvr6+vPXW\nW3Tq1IktW7aQkZFRrM6MjAxCQ0MZM2YM27Zt48SJE3Ts2JHCwkJGjRoFwIABAxg3bhze3t5WfQ+F\nEELYFxlWeEjjxo3D09OTmTNnml7r0aMHp06dIjU1lcjISMaOHcsvv/xCZmYmMTExrF27lqVLl3L9\n+nWWLFlCSEgIkZGRaLXFby07Oxs/Pz+ioqJ49913WbFiBYqiMG3aNFasWEFsbCy7d+82G064W53t\n2rWjYcOGzJw5k8DAQLZv3w7AlStXyM3NlcRACCEE2vs47IVd9RzcycSJE+nXrx9hYWG4ubmxf/9+\nDh06RFBQEABGo5Hs7GzS09Np1aoVAG3btmXHjh1m9VSvXp0lS5awcuVKCgoKqFChAhcvXqRs2bJU\nrVoVgGXLlpldc686b6pcuTKPP/44qampnDp1ildffbVE3wMhhBCOyRF7DhwiOcjJycHFxYVz584B\noNPp6NWrF0OHDjUrpygKmv/+JRiNxmL1REZG4u7uzkcffcSRI0f48MMP0Wq1ty1raZ236tGjB/Hx\n8WRlZTF69Oj7ukchhBClkyPOObCnXozbKiwsZM6cOcTExLB9+3YyMjJo1qwZiYmJGI1Gbty4wfTp\n0wHw9PQkJSUFgOTk5GJ15eTkmOYNbNu2Db1eT5UqVTAYDJw7dw5FURg6dCiXL182XXOvOjUaDQZD\n0RKj7du35+eff+by5cvUrWub5U6FEELYF0d8WsHuk4M1a9bQsWNHHnvsMUaPHs306dNp1aoVbdu2\npU+fPvTr14/GjRsDMGzYMD766CMGDx6Ms7Nzsbq6d+/O6tWrGThwIM2aNSM7O5uNGzcyZcoUQkND\n8ff359lnn8XNzc10zb3qbNOmDaGhoZw4cQKdToeXlxcdO3ZU7w0RQgjhUJw0GosPe6FRFEWxdSNK\nixs3btC3b1/WrFlDxYoV71leNl5Sl2y8ZB2y8ZL6ZOMl61Br46XFlZ6yuGzIpeOqtOF+2X3PgaM4\nePAgfn5+BAcHW5QYCCGEeDQ4Ys+BQ0xIdAQtWrRg8+bNtm6GEEIIO+OIExIlORBCCCFUZE8TDS0l\nyYEQQgihIuk5EPfFFpMDx7rYZkLVmHNHrB7z8TL5Vo8JoLlxxSZxr2kq2SSurWbYGBu+aPWYwzQ6\nq8cEMNho2ngtbZ5N4h6/Xt4mcdVSknMJPvjgAw4dOoRGoyE8PJxmzZqZzsXExLB582a0Wi1NmjRh\nwoQJDxxHkgMhhBBCRSXVc7B3715Onz7Nhg0bSE9PJzw8nA0bNgBFewetXLmS7777jjJlyjBw4EAO\nHjxIixYtHiiWPK0ghBBCqKiknlbYvXs3Pj4+AHh5eXHp0iXy8op6d5ydnXF2dubq1asUFhZy7do1\nKlV68N5E6TkQQgghVFRSPQcXLlwwLfoHULVqVbKzs3F1daVs2bIMHz4cHx8fypYtS5cuXfD09Hzg\nWNJzIIQQQqjIWau1+Lgft65hmJeXx7Jly4iPj2f79u0cOnSIX3/99YHbbHfJQadOncjPv/NEsvj4\neACOHTvGwoULgaLdEkva6NGjzbZuBkhMTCQsLIzs7GwmT54MwM8//8xff/1V4vGFEEKUDhonjcXH\n3dSsWZMLF/63Iun58+epUaMGULSDcL169ahatSo6nY6nn37atC/Qg7C75OBeli9fDkDDhg0JDQ1V\nLc78+fMpV67cbc/VqFGDiIgIADZu3CjJgRBCiDvSOmksPu6mXbt2JCQkAJCamkrNmjVxdS1a8rlO\nnTqkp6ebvtSmpKTwxBNPPHibH/jK+/DGG2+QlZUFQGZmJj179kSv1zN+/HgCAwPp3bs3O3fuNLvm\n119/JSAggKCgIPr3709ubi6ffvopx48fJyQkhOTk5GLJwcmTJwkODqZ///783//9n9nuilDU7TJ0\n6FCCgoLw8/Pj8OHDACQlJfHmm2/Su3dv1qxZA/yvB+P48eP06NGD/v3788MPPwCQkZFBz549SUpK\nYtu2bYwfP57Fixfz8ccfm2INGDDgobp0hBBClA4aJ63Fx920atWKxo0b4+/vz4wZM5gyZQpxcXF8\n//33VK9enUGDBhEcHExAQAANGzbk6aeffuA2W2VCoo+PD4mJifTr14/t27fzyiuvsHXrVnQ6HdHR\n0Zw7d47g4GBTRgTw119/MWnSJBo1asSCBQvYsmULb7/9NitWrGDx4sW33T55+vTpRERE8MQTTxAT\nE0NMTAzDhg0znc/OzsbPzw8fHx92797NihUrWLhwIdOmTWP9+vVUqlSJ//u//8Pf3990zZIlSwgJ\nCcHHx4cpU6aYxWvXrh0NGzZk0qRJ1KxZk6CgIEaNGsWVK1fIzc3F29tbhXdTCCGEI7nXcMH9GDt2\nrNnPt37O+Pv7m31+PQyrJAevvPIKs2bNMiUHU6dOJSYmxjRXwN3dHZ1OR25urumaatWqMWfOHK5f\nv8758+fp1q3bPeMcPnyYSZMmAVBQUEDTpk3NzlevXp0lS5awcuVKCgoKqFChAhcvXqRs2bJUrVoV\ngGXLlpldk56eTqtWrYCiuQ07duy4bezKlSvz+OOPk5qayqlTp3j11VctfHeEEEKUZvcaLrBHVkkO\n6tevz/nz5zl79ixXrlwxPV5x60zLgoICtLfM1Hz//fcZPHgw7du3Z+XKlVy9evWeccqXL8/atWvR\n3OFZ0cjISNzd3fnoo484cuQIH374IVqtFqPReMc6FUUx1Xe3cgA9evQgPj6erKwsRo8efc/2CiGE\nKP2cnG2znfrDsNqExA4dOjB//nw6deoEQNOmTU1DA2fPnkWr1eLm5mYqn5ubi4eHBwUFBfznP/9B\nr9cD5gnF33l7e5u+2W/dupXdu3ebnc/JycHDwwOAbdu2odfrqVKlCgaDgXPnzqEoCkOHDjWbq+Dp\n6Wma8Xm7oQyNRoPBULTnefv27fn555+5fPkydevaZv91IYQQ9qWknlawJqslBy+//DJff/21qbu9\nS5cuGAwGgoKCGD16tGn2/02BgYEMHz6c0NBQgoKC+PLLL/n1119p2LAhvXr1um2MCRMmsGzZMgID\nA4mLi6NhQ/N9BLp3787q1asZOHAgzZo1Izs7m40bNzJlyhRCQ0Px9/fn2WefNUtShg0bxkcffcTg\nwYNxdnYuFrNNmzaEhoZy4sQJdDodXl5edOzY8WHfLiGEEKVESU1ItCaNcrev4uK+3Lhxg759+7Jm\nzRoqVrz3djR5V69ZoVXmHqmNl5xts/ESyt2Hn9SSbaONl2oW2uZRXmN569/vdRttvGQr5Qsu2SSu\nrTZealpLnd+pHW2fs7hs++RdqrThftlPmuLgDh48iJ+fH8HBwRYlBkIIIR4NGq3G4sNeyN4KJaRF\nixZs3rzZ1s0QQghhZ5x0jjchUZIDIYQQQkX2NNHQUpIcCCGEECrS2tFEQ0tJciCEEEKoSHoOxH3R\n7dtk9Zi2eGoAYK5703sXKmGLzv1o9ZgAGA02CVtTW2CTuBqD3iZxy+T8YfWYf5Z93OoxATx11+9d\nSAW5WttMrvaq7Hhj9HejtaOJhpaS5EAIIYRQkT2tX2ApSQ6EEEIIFTnpJDkQQgghxC0csefA8Vp8\nFzt27GDdunUAxMfH37bMrVs4l4Sbe2n/3c0dJ4UQQjzatE4aiw97Uap6Dtq3b2/68/Lly2+7bfLS\npUtLNGbPnj1LtD4hhBCliz2tfGgph00O9Ho9YWFhZGZmUrZsWT788EOSkpI4ceIE1apV4/jx44SE\nhBAUFMSqVau4evUq48aNY9CgQSQnJ3P06FGmTZuGRqOhZcuWjBs3zqz+VatWkZCQgNFo5MUXXyQk\nJITLly8zduxY8vLyqFixIvPmzWPVqlVUqVIFf39/xowZw59//knTptafmS+EEMI+OeI6B47X4v/6\n6quvqF69OuvXr6d3795s377ddO7tt9/G1dWVxYsXA5CWlsbKlStp0qSJqcyMGTOYNm0a69ev56+/\n/iIzM7NYjHXr1vHZZ58RFxdHXl4eK1eu5Pnnn2fdunU8++yzZltCJyUlUVhYyIYNG+jWrRu5ubkq\n3r0QQghH4YhbNjtsz0FqairPPvssULT9MxSN/9/OU089hU5nvpvaqVOn8Pb2BuDDDz8sdk25cuUI\nDAykTJky5OTkkJuby9GjRxk5ciQAb731FgDHjh0D4OTJk7Rs2RKA5s2bU65cuYe8QyGEEKWB1tnx\nPmodr8X/5eTkhNFo2da4f08MALTaO3eaZGZmsmbNGr788ktcXFzo2rXrPWMqimJWp6VtE0IIUbrJ\nsIIVNW3alD179gCQmJjIv//9b7PziqLc9XovLy8OHToEQHh4OOnp6aZzOTk5VK1aFRcXF1JTU8nM\nzESv19OkSRNTzPXr1/Pll1+arvH09CQlJQWA/fv3U1Bgm9XqhBBC2BeNk9biw17YT0vuk6+vL9eu\nXSMwMJDIyEjeeOMNs/MNGzakV69ed7x+woQJzJo1i4CAACpVqoSXl5fZtS4uLvj7+/PNN9/g7+/P\ntGnT6N+/PwcOHCAoKIgff/yRl19+2XRN+/btuX79OoGBgXzzzTe4u7uX/E0LIYRwOI6YHGiUe33F\nFqop+Gm91WOefqqL1WOC7K1gFVrbrEdvq70VNIXW32/g5KO2t4LGxSZxXXW2+V2uUF6duWK/je5r\ncdkn569TpQ33y2HnHAghhBCOQKtztnUT7pskB0IIIYSK7jYB3l5JciCEEEKoyJ7mElhKkgMhhBBC\nRZIcCCGEEMKMRoYVxP3QeD9n9ZiPl8m3ekywzZMDI9w7WD0mwKLzO2wS15j6k03i6jPT711IBV+O\njLV6zBZH9lg9JsANXUWbxP3kp9M2iTukTT2bxK1QXp16pedACCGEEGacdI73Uet4LRZCCCEciAwr\nCCGEEMKMDCsIIYQQwowjJgd23eK4uDi+//77Yq+3bdv2vusKCgoiLS2tJJolhBBCWEyj1Vp82Au7\n7jno2bOnrZsghBBCPBStU8ntFfHBBx9w6NAhNBoN4eHhNGvWrFiZuXPncvDgQaKioh44jlWSg7i4\nOHbs2MH58+eZP38+27ZtY8uWLWi1Wnx8fBg4cCBHjx5l2rRp6HQ6dDod8+fPJzIykipVquDv78+Y\nMWP4888/adr0fxv4BAUFMWnSJBo0aEB0dDQ5OTkMGzaMcePGce7cOa5evcqIESPo2LHjbdv11Vdf\nER0djbOzM97e3kyZMuW2db7zzju89957ZGVl0bJlS7799lt27NjBrl27WLBgAc7Ozri5ufHxxx9z\n4MABVq1axdWrVxk3bhxNmjSxxlsshBDCTmlL6GmFvXv3cvr0aTZs2EB6ejrh4eFs2LDBrMzJkyf5\n+eefcXZ+uP0crNaHcfbsWWJiYigoKCA+Pp7Y2FhiYmL47rvvyMrKIi4ujoCAAKKionj77bfJzs42\nXZuUlERhYSEbNmygW7du5Obm3jHOpUuXeP7554mOjmbBggUsWrTojmVXrlzJokWLiI2NpUmTJly/\nfvudz3766Sdu3LjBZ599xjPPPMP58+dNsebMmUN0dDSurq7s3LkTgLS0NFauXCmJgRBCiBIbVti9\nezc+Pj4AeHl5cenSJfLy8szKzJo1i9GjRz90m602rNC0aVM0Gg1Hjhzh9OnTBAcHA5Cfn09mZiYv\nvfQSU6dO5ffff8fX1xcvLy/TtSdPnqRly5YANG/enHLl7rytppubG0eOHGHDhg1otdq7JhJdu3Zl\n+PDhvP7663Tt2vWO9aanp9OqVSsAXnzxRcqUKXrbqlatysSJEzEYDJw5c4ZnnnkGFxcXnnrqKXQ6\n3f29QUIIIUqlkpqQeOHCBRo3bmz6uWrVqmRnZ+Pq6goU9dK3adOGOnXqPHQsqyUHN7s4nJ2d6dCh\nAxEREcXKfPHFFyQmJhIWFsa//vUv0+uKopjtamU0GotdW1hYCMDXX3/NpUuXWLduHbm5ufTq1euO\nbRo6dCjdunUjISGB/v37Ex0dfds6FUXB6b9jRhqNxnQ+PDyc5cuX4+XlZXY/khgIIYS4Sa2nFRRF\nMf05NzeXuLg4Vq9ezblz5x66bqtPjWzcuDHJyclcu3YNRVGYMWMG169fJzo6mtzcXF5//XX69+/P\nsWPHTNd4enqSkpICwP79+ykoKADA1dXVNPywf/9+AHJycqhbty5arZbvv//eVPbvjEYj8+fPp0aN\nGgwYMIAWLVqQlZV12zo9PDxM8Xfu3InBYAAgLy+PWrVqcfnyZZKTk9Hr9SX9dgkhhHBwJTWsULNm\nTS5cuGD6+fz589SoUQOAPXv2cPHiRfr160dISAipqal88MEHD9xmqz+tULt2bYKDg+nXrx9OTk74\n+PhQrlw5PDw8GDlyJBUrVkSn0zFz5kxiY4vWTm/fvj0bN24kMDAQb29v3N3dAejTpw8RERE8/vjj\neHh4APDKK68wbNgwDh48yJtvvsljjz3G4sWLi7VDq9Xi4uJCnz59qFixIvXq1aNhw4a3rbNjx45s\n3LiRgIAA2rRpQ+XKlQHo27cvAQEBPPHEE7z99tssWrSId9991xpvoxBCCAehKVMyvcnt2rVj0aJF\n+Pv7k5qaSs2aNU1DCq+++iqvvvoqABkZGYwfP57w8PAHb7Nya7+EuK3c3FySk5Pp3Lkz586do3//\n/sTHxz90vfrsP0qgdfdHKaFf0vul0d9+sqeaZOMl65CNl9T3RCXb/H875xHbeKlOFRdV6r26cY7F\nZSu8Ofau5+fMmcMvv/yCRqNhypQpHD16lIoVK/Lyyy+bytxMDuz+UUZH5+LiwrfffsvKlSsxGo2M\nHz/e1k0SQgjhIDQluM7B2LHmyYO3t3exMnXr1n2oxAAkObCIs7MzH3/8sa2bIYQQwhFpSy45sBZJ\nDoQQQgg1SXIghBBCiFvZ054JlpLkwIaMFapYPabmxhWrxwTAaLB6SFtNDBxRs71N4i4696NN4lao\n63XvQioISPin1WNml7fNP5k6pdAmcR+vVsEmcbOv2uax8Dpq/ZNso4ngD0OSAyGEEEJF0nMghBBC\nCHMy50AIIYQQZiQ5EEIIIcStSnKdA2txvIGQe0hOTiY0NLTY60FBQaSlpVlUx/vvv8+ZM2fMXktL\nSyMoKKhE2iiEEOIRotVaftgJ6Tm4jQkTJti6CUIIIUqJktpbwZocPjnQ6/WEhYWRmZlJ2bJlefPN\nN8nPz2fs2LEcP36czp07ExISYip/5coVwsLCuHz5MoWFhUycOJHGjRvzyiuv0KhRI9q1a8fmzZuZ\nNGkSbm5ujBw5Ep1Ox1NPPWWq47vvvmPVqlWUKVOGJk2aEBYWRlZWFu+99x5arRaDwcBHH31UIntq\nCyGEcHB21CNgKcdr8d989dVXVK9enfXr19O7d2/y8vJIT09n+vTprF+/nujoaLPykZGRNG/enKio\nKMLDw5k5cyYAZ86cYfjw4fj5+ZnKrl27Fl9fX6KioqhZsyYA+fn5LF26lLVr1xIdHc3Zs2fZt28f\nCQkJPPfcc0RFRTFhwgTTts9CCCEebRqtk8WHvXD45CA1NZVWrVoB0KVLF7y8vGjUqBHly5fHxcWF\nv286mZKSQtu2bQFo2rQpp08X7TpWvnx56tevb1Y2PT2dli1bApiuOXnyJFlZWQwaNIigoCBOnz5N\nVlYW7dq1Y9OmTcyaNYuCggJatGih6n0LIYRwEFonyw874fDDCk5OThiNRrPXypS5821pNBqzhOHm\ntc7OzsXKKoqC9r/dQbeWa9KkCStXrixWftOmTSQlJTFv3jzefPNNevTocf83JIQQonSRYQXra9q0\nKXv2FO2xnpiYyIEDB+5ZPjk5GYCDBw8W6y24laenJykpKQCmazw9PUlPT+evv/4CYOHChZw7d46t\nW7dy4sQJfHx8GDlypOk6IYQQjzaNs87iw144fM+Br68vu3btIjAwkDJlytCzZ0+OHj16x/LBwcGE\nh4cTHByMoihMnjz5rmVHjRrF999/T4MGDYCi4Yfw8HAGDx6MTqejUaNG1KxZkyeeeIIpU6ZQoUIF\nnJycmDhxYonfqxBCCAdkR8MFltIofx+UF1ZzI9/6myDZauMlTcE16wd1Kj5UZA2P2sZLTpf/tElc\n46W/rB4z26uD1WMCVHU23ruQCmKO5dgkbqtabjaJ26JOZVXqNaYlWVxW26CdKm24Xw7fcyCEEELY\nNQfsOZDkQAghhFCTxvGm90lyIIQQQqhJkgMhhBBC3ErROt5HreO1uBTJN1p/HOqappLVYwLU1BZY\nPaYx9SerxwTbTQwc4d7BJnFD+ja2SdwG71h/I7TK5Wwzdqy5nm+TuF5VKtgkrncV20wmVo1GY+sW\n3DdJDoQQQgg1OeAiSJIcCCGEECpSZM6BEEIIIcxIciCEEEIIMw44IdGidEav1+Pn58e4cePUbk8x\nQUFBpKWlcfHiRbp06cLcuXMfqr6ePXuSkZHB8uXL77kPw9+NHj2a69evm72WmJhIWFjYQ7VJCCFE\n6aVotBYf9sKidCY7O5uCggJmz56tdnvuKD09nccff5wxY8aUSH1Dhgy572vmz59fIrGFEEI8Quzo\nQ99SFiUHM2fO5I8//mD8+PHUrl2bM2fOkJGRQVRUFAsXLuSXX37BYDAQGBhI165dOXfuHBMmTECv\n1+Pk5MSMGTOoXbu2qb4rV64watQoCgoKKCgoYPLkyeTl5RETE8PChQsBaNu2rWknxJttyMrKYu7c\nuWRnZ9O5c2c6duxIYmIiCQkJhISE8N5771GhQgUCAwPp2LGj6doZM2Zw4MABPD090ev1AISFhdG5\nc2eef/55Jk+ezJkzZygoKCA0NJQmTZoQFBTE+vXrMRgM9O3bl3Xr1tGjRw+2bNlCRkYG48aNo1Kl\nSnh4eJjixMTEsGXLFrRaLT4+PgwcOPDh/naEEEI4Pgd8lNGidGbcuHF4enoyc+ZMoGiYYd26dRw4\ncIDMzExiYmJYu3YtS5cu5fr16yxYsICBAwcSGRlJ//79WbJkiVl9u3fvxt3dnaioKObMmWPa/vhe\nbWjTps1dew6OHTvGnDlzzBKDkydPsn//fj7//HPGjBnDqVOnzK7ZunUrOp2O6OhoFi1axPTp06lc\nuTIDBgxg+fLlLFmyhKFDh+Lm9r+NQJYsWUJISAiRkZFo//uIypkzZ4iPjyc2NpaYmBi+++47srKy\n7v3mCiGEKN00WssPO/FAsySaNWsGwP79+zl06BBBQUWLkRiNRrKzszlw4ACnTp1i6dKlGAwGqlat\nanZ9ixYt+Pjjj5k8eTKvvPIK7du3N+sleFD16tWjSpUqZq+dPHmS5s2bo9VqqVWrFvXq1TM7n5KS\nQtu2bQFwd3dHp9ORm5vLG2+8wdtvv41Wqy02pyA9PZ1WrVoBRT0cO3bs4MiRI5w+fZrg4GAA8vPz\nyczMNOsxEUII8eixp7kElnqg5MDZuWj1Kp1OR69evRg6dGix8wsWLKBmzZq3vb5mzZps2rSJ5ORk\nYmNjOXjwIG3atDErU1hYeMf4mlu6aG4td7Ndt1IUxfTtHooSmNuVuamgoACtVkthYSHXrl3DaDSi\n1+vN6lYUxdSGm/U5OzvToUMHIiIi7thuIYQQjyCnUvq0wp00a9aMxMREjEYjN27cYPr06QA0b96c\nbdu2AUVDCFu2bDG7bteuXezatYvnn3+eSZMmkZKSgqurK+fPnwfg119/JT//zsuFuri4kJ2dDcC+\nffvu2kZPT09SU1NRFIXMzEwyMzPNzjdt2tTUa3H27Fm0Wi1ubm6sXr0aX19ffHx8WL16dbE6U1JS\nAEzXNm7cmOTkZK5du4aiKMyYMaPYkw1CCCEeQY/KsMJNrVq1om3btvTp0wdFUejbty8AISEhhIeH\ns3XrVjQajWmuwk0eHh689957fPrpp2g0GkJDQ/H29qZChQr4+/vTsmVL6tSpc8e43bt3Z+zYsSQk\nJNCwYcO7ttHb25sGDRrQp08fnnjiCby9vc3Od+nShb179xIUFIReryciIoLMzEy+++471q9fj9Fo\nxM/Pjy5dupiuGTZsGOPHj2ft2rXUq1cPvV5P7dq1CQ4Opl+/fjg5OeHj40O5cuXu9y0VQghR2tjR\nh76lNMqtferCqi5euWr1mNcKbfPXXVOfbfWYxqNJVo8JoG3UziZxZeMl9Rla97B6TACn65dtEnf3\nX7b5UGtbq7xN4par4KJKvTcuX7S4bFm3qvcuZAWONxAihBBCOJIS7Dn44IMPOHToEBqNhvDwcNMD\nAlA0ZD9v3jycnJxo3749w4ee6fyxAAAgAElEQVQPf+A4jtfXIYQQQjgSjcby4y727t3L6dOn2bBh\nA++//z7vv/++2fkZM2awaNEiYmNjSUpK4uTJkw/cZEkOhBBCCBUp2jIWH3eze/dufHx8APDy8uLS\npUvk5eUBRWvtVKpUiVq1aqHVannxxRfZvXv3A7dZkgMhhBBCTSX0tMKFCxfM1vKpWrWq6cm97Oxs\nszWFbj33IGTOgQ1VvH7B+jGtHrGIxqC3ekx9ZrrVYwJUqOtlk7i2mhi4eF2qTeKGeyRYPWbNp7tb\nPSaANv/eq8iq4YeTtln2t4aLbRaPa1RBnXoVlZZPVvN5AkkOhBBCCBWV1Gd4zZo1uXDhf18qz58/\nT40aNW577ty5c3dciNASMqwghBBCqMioKBYfd9OuXTsSEop6zFJTU6lZsyaurq4A1K1bl7y8PDIy\nMigsLCQxMZF27R78sWrpORBCCCFUZCihnoNWrVrRuHFj/P390Wg0TJkyhbi4OCpWrMjLL7/M1KlT\nTZsT+vr64unp+cCxJDkQQgghVFSScwPGjh1r9vOtq/62bt2aDRs2lEicew4r3OzCuJPt27dTUFBw\nx/NhYWEkJibef8uAjIwMevbsCcCWLVvo3Lkzv/zyywPVBZCWlmbaQXLYsGH3de2xY8dYuHBhsddD\nQ0NLZEdJIYQQpZNRsfywF3dNDjIyMti6detdK1izZg16vfoz0Xft2sV7773H008/XSL1LV269L7K\nN2zYkNDQ0BKJLYQQ4tGh3MdhL+46rBAREcHhw4dZvHgx/fv3JywsjMuXL1NYWMjEiRM5ceIEBw8e\nZPDgwaxZs4a5c+dy+PBhbty4QUBAAH5+fretd+fOnXz88ceUK1eOatWqMWfOHCZNmkTnzp3p2LEj\niYmJJCQkEBISAkBSUhI7duwgJSUFNzc3RowYYfq2HhoaSr9+/di7dy9nzpwhIyODqKgonJycAPjz\nzz8ZOXIkOp2Op556ytSGtm3bkpyczPHjx4mIiECr1eLi4sKsWbP48ccfOXz4MJMnT2bTpk3s27eP\nLl26EBMTw8KFC1mxYgVbt26ldu3apgUo8vLyCA8P59KlSxgMBiZOnFhskychhBCPHnvqEbDUXXsO\nBg0aRJs2bQgJCSEyMpLmzZsTFRVFeHg4M2fOpEePHtSoUYMVK1agKAp16tQhNjaWdevWsWDBgjvW\nGx0dTVhYGNHR0XTp0oXc3Ny7NrJdu3a88MILvPvuu7Rp0+aO5fR6PevWrTMlBgBr167F19eXqKio\n2z7W8f777/Ovf/2LqKgoWrduzdq1a+nRowenTp0iNTWVyMhIszGey5cvExsby4YNG/jwww85ceIE\nAJGRkbzwwgtERkYydepUZs+efdd7EkII8WhQFMXiw15YPCExJSXFNE7ftGlTTp8+bXa+bNmyXLp0\nCX9/f5ydncnJybljXa+++ipTpkyhW7dudOnSxfSc5sO6dQOKm9LT03n11VeBot6Cn376qdj55s2b\nm84vXrwYgIkTJ9KvXz/CwsJwc3MzlT99+jT/+Mc/KFu2LGXLlqVx46KFZw4cOMDFixfZvHkzANeu\nXSuRexJCCOHYSuppBWuyODnQaDRmWY3RaDQ7v3fvXvbs2UNUVBTOzs60bNnyjnX16NGDF154gW3b\ntjFs2DAWLFiA5pYVpAoLCy2+gVvnOzg7Oxc7rygKWq32tm2+XV03y+bk5ODi4sK5c+fuWN/Nn2/G\nnjRp0l3vWwghxKOn1A0raLVa0wd106ZNTeP8Bw8epH79+kBR0mAwGMjJyeGxxx7D2dmZ7du3YzAY\n7vgUwyeffEKZMmXo06cPvr6+pKen4+LiYloHet++fXdttEaj4dq1a1y7do1jx47dtaynpycpKSkA\nt32qoH79+hw4cACAn3/+mSZNmlBYWMicOXOIiYlh+/btZGRkmMp7eHiQnp5OQUEBeXl5prqbN2/O\ntm3bADh58iSrV6++a7uEEEI8GkrdsIKXlxdHjx7lgw8+IDQ0lPDwcIKDg1EUhcmTJwPQpk0b+vbt\ny7Jly1ixYgWBgYH4+PjQoUMHpk6dett6a9euzYABA3Bzc8PNzY0BAwZQq1Ytxo4dS0JCAg0bNrxr\nowMCAujduzdeXl6mbv07CQ4OZtSoUXz//fc0aNCg2PmJEycybdo0NBoNlSpVYubMmaxZs4aOHTvy\n2GOPMXr0aKZPn87AgQMBqFy5Mj169MDf35+6devStGlTAAIDAxk/fjx9+/bFaDQyYcKEu7ZLCCHE\no+Hufdb2SaPYU6ryiNFn/2HrJliNpvCG1WNe/yHW6jEBKrR9xSZxj06ZbpO4Ntt4Kayj1WPWnLzE\n6jEBylz83SZxp6fYZuOlPs1ttPHSY273LvQATv+VZ3HZx6u5qtKG+yUrJAohhBAquteeCfZIkgMh\nhBBCRaX6aQUhhBBC3D8H7DiQ5EAIIYRQk9GuFka2jCQHtvT7QauHNDZ80eoxAcrkWH/y5ZcjbTMh\nMSDhnzaJ2+CdIJvEDfe4++Zsavlg1oNt6PYwpoyzzbzzauUr2STuus222VSuRR3b3K9aExKl50AI\nIYQQZhxxESRJDoQQQggVGRyw60CSAyGEEEJFDpgbSHIghBBCqMkR1zm4694KpU1+fj6dOnV66Hre\nf/99zpw5Q15eHjt37iyBlgkhhCitDEbLD3vxSCUHJWXChAnUq1eP1NRUkpKSbN0cIYQQdsyoKBYf\n9qLUDyvk5eUxYsQIbty4wT//WfSI2S+//MK8efMoU6YMtWrVYvr06Rw4cICYmBg0Gg2//fYbnTt3\nJiQkhK+++oro6GicnZ3x9vZmypQpBAUFMWnSJCIiIsjLy6Nq1ap88cUXxMfHo9Fo2Lx5M6mpqYwf\nP97Gdy+EEMLWHHFCYqnvOdi0aRP169dn3bp1pt0eZ8yYwZIlS1i7di3VqlUjPj4egMOHDzNr1izW\nr19PVFQUACtXrmTRokXExsbSpEkTrl+/bqp70KBB+Pr6MnjwYJ566inT1s/bt2+na9euVr5TIYQQ\n9khvUCw+7EWp7zlIT0+ndevWQNH20hcuXCAnJ4cRI0YAcPXqVapUqYK7uzuNGjWifPnyZtd37dqV\n4cOH8/rrr9O1a1fKlSt32zjdu3fnm2++oUmTJmRkZJi2chZCCPFos6fhAkuV+uRAURS02qIOEqPR\niLOzM9WrVzf1DNyUnJxMmTLF346hQ4fSrVs3EhIS6N+/P9HR0beN0759exYsWMCePXvo2NH6W8kK\nIYSwTzKsYIc8PT1JSUkBihKASpWKluU8efIkAFFRUfz666+3vdZoNDJ//nxq1KjBgAEDaNGiBVlZ\nWabzWq2WwsJCAJydnWndujULFy6kW7duat6SEEIIB2JULD/sRalPDnr06MHBgwfp378/p06dAooe\nRRw/fjx9+/Zl3759PPnkk7e9VqvV4uLiQp8+fejfvz8ajcY0bwGgUaNGfPvtt6xcuRKA1157DY1G\nw+OPP67+jQkhhHAIBqNi8WEvSv2wgpubm9kQQmhoKACff/65Wbm2bdvStm1b08/JyUUbjgwZMoQh\nQ4aYlb21vlvXOdi1axf+/v4l13ghhBAOT+YcPMKGDBlCuXLlGD58uK2bIoQQwo7o7ahHwFKSHJSQ\n5cuX27oJQggh7JA9DRdYSpIDIYQQQkUyrCCEEEIIM3a0tpHFNIrigClNKTEr8YTVYw5rU9fqMQH+\nzNdbPWaBjf6PrF7eNjl35XJONomrsdE/ITk3rL9LzbQqja0eE+CTP7bYJK5S5vaLvqke18nZJnGd\naz6hSr3rD2VaXNa/eR1V2nC/pOdACCGEUJE9LYtsKUkOhBBCCBXJnAMhhBBCmFF7+WS9Xk9YWBhZ\nWVk4OTkxc+ZM6tWrd9uy7777LjqdjlmzZt21zlK/QqIQQghhS0ajYvHxIL7++mvc3NyIjY3lnXfe\nYe7cubctl5SUxB9//GFRnZIclICwsDASExPNXrt1tUUhhBCPLoNi+fEgdu/ezcsvvwzAc889x/79\n+4uVKSgoYOnSpQwbNsyiOmVYQQghhFCR2nMOLly4QNWqVYGiPYE0Gg0FBQXodDpTmWXLlhEQEICr\nq6tFdUpycJ/i4uL46aefyMvL488//+Stt96ydZOEEELYsQJDyT12+/nnnxfbG+jQoUNmP/99hYLf\nf/+dlJQURowYYdo36F4kOXgAJ0+e5Msvv+Ty5ct0796dZ599lnnz5rFq1SpbN00IIYSdKcnlk/38\n/PDz8zN7LSwsjOzsbLy9vdHr9SiKYtZr8OOPP5KVlUXv3r3Jy8vj4sWLrFixgsGDB98xjiQHD6B1\n69aUKVOGqlWrUqlSJXJycnj33Xfp2LGjqYzMORBCCAHq763Qrl074uPjeeGFF0hMTCz2+fPWW2+Z\nermTk5P58ssv75oYgExIfCBG4/+6iBRFQaPR2LA1Qggh7JnBqFh8PAhfX1+MRiMBAQHExMQwZswY\noGhDwAMHDjxQndJz8AAOHjyIwWDg0qVL5OfnU7lyZVs3SQghhJ1Su+fg5toGfzdkyJBir7Vt29ai\nnm1JDh5AnTp1GDlyJKdPn2bUqFHs2bPH1k0SQghhpwoKrb8PyMOS5OABeHh4MG7cONPPPXr0KFbG\n0hmhQgghSje1ew7UIMmBEEIIoSJJDh4BPXv2tHUThBBCOBBJDoQQQghhplCSAyGEEELcSnoOxH0J\naVvX6jEfdGOPh+Wpu271mDd0Fa0eE0CnFNokruZ6vk3iavP/skncauUrWT3mJ39ssXpMgOEe3WwS\nd07+MZvE1elt87uslpJcPtlaJDkQQgghVCQ9B0IIIYQwI8mBEEIIIcxIciCEEEIIMwaj4805KNUb\nL3Xq1In8/DtPbLmfnRO3b99OQUFBSTRLCCHEI0TtjZfUUKqTg5K0Zs0a9Hq9rZshhBDCwdwoNFp8\n2AuHHFbIysrivffeQ6vVYjAYeO6558jPz2fcuHHk5+fTrVs3fvjhB1P5sLAwKlSowG+//UZOTg4z\nZ86kUaNGACxYsICkpCQqV67Mv//9b86fP897770HQGFhIbNnz2b//v0cPHiQwYMHs2bNGj7//HO2\nbNmCVqvFx8eHgQMHcvToUaZNm4ZOp0On0zF//nzc3Nxs8v4IIYSwH/bUI2Aph+w5SEhI4LnnniMq\nKooJEyag0+nueU1hYSFr1qxh5MiRfPLJJwBcunSJzp0789lnn3Hp0iWOHz/O+fPnGT58OFFRUbz5\n5pusW7eOHj16UKNGDVasWMG5c+eIj48nNjaWmJgYvvvuO7KysoiLiyMgIICoqCjefvttsrOz1X4b\nhBBCOABHHFZwyJ6Ddu3aERISwpUrV+jcuTPVq1cnJyfnrtc899xzALRo0YI5c+YA4Orqire3NwDu\n7u5cuXKFevXqMWPGDBYtWsTly5dp3LixWT1Hjhzh9OnTBAcHA5Cfn09mZiYvvfQSU6dO5ffff8fX\n1xcvL6+Svm0hhBAOyJ4+9C3lkMlBgwYN2LRpE0lJScybN89sM6TCwtuvTme8ZbaoRqMBwMnJyayM\noigsXLiQ559/noCAAOLj4/nxxx/Nyjg7O9OhQwciIiKKxfjiiy9ITEwkLCyMf/3rXzzzzDMPeotC\nCCFKCUdMDhxyWGHr1q2cOHECHx8fRo4cyapVqzh//jwA+/btu+01N18/cODAXb/V5+Tk4OHhgaIo\nbN++3TQJUaPRYDAYaNy4McnJyVy7dg1FUZgxYwbXr18nOjqa3NxcXn/9dfr378+xY7ZZdlQIIYR9\nKSw0WnzYC4fsOXjiiSeYMmUKFSpUwMnJiY8++ojw8HCCgoJ48cUXTT0Dt7px4wZDhw7l7NmzfPTR\nR3esu0+fPkyfPp06deoQFBTEpEmT2LlzJ23atKFv376sXbuW4OBg+vXrh5OTEz4+PpQrVw4PDw9G\njhxJxYoV0el0zJw5U823QAghhIMwOmDPgUZRFMdr9X0KCwujc+fOdOzY0dZNMZN39ZrVY9pq46Xy\n+itWj/nIbbykt/7vE9hu4yWjDTZecrLRvcrGS1aKW6m6KvV2mP8fi8v+OPpFVdpwvxyy50AIIYRw\nFIoD9hw8EsnBrFmzbN0EIYQQjyhHHFZ4JJIDIYQQwlYU+5lnaDFJDoQQQggVGQyOlx1IciCEEEKo\nSOYciPvy1zWD1WPW0uZZPSZArtb6Tw588tNpq8cEeLxaBZvE9apim7g/nCz+6LA1rNucbPWYxyY2\nsXpMsN1TA2NdGtok7qxlfW0SVzfkA1XqleRACCGEEGaMDrhigCQHQgghhIqk50AIIYQQZhwxOXDI\nvRUeVqdOncjPv78VuNq2batKWSGEEKWbwWC0+LAX0nMghBBCqEjWObBDeXl5jBkzhqtXr3L9+nUm\nTZpkOpeZmUlYWBgGg4HatWsze/ZssrOzCQ8PR6/Xo9FoeP/996lXrx4ACxYsICkpicqVK/Pvf/+b\n/Px8wsLCuHz5MoWFhUycOJHGjRvb6laFEELYIUdcIbHUDytkZ2fj5+dHVFQU7777LitWrDCdmz9/\nPm+99Rbr1q2jZs2apKSksGDBAnr16kVUVBR9+/Zl8eLFAFy6dInOnTvz2WefcenSJY4fP05kZCTN\nmzcnKiqK8PBw2YlRCCFEMYpRsfiwF6U+OahevToJCQkEBAQwZ84ccnNzTeeOHj1Kq1atAPjXv/5F\n8+bNSUlJoU2bNkDR3IGjR48C4Orqire3NwDu7u5cuXKFlJQU0/yCpk2bcvq0bZ6rF0IIYb8kObBD\nkZGRuLu7Exsby9SpU83OOTk58fcdqzUajek1vV6PVqs1lb2VoihmZQGMRgccWBJCCKEqR5yQWOqT\ng5ycHDw8PADYtm0ber3edK5Jkybs2bMHKJpPsGvXLpo2bUpyctHKaz///DNNmtx5RbRbyx48eJD6\n9eurdRtCCCEclNo9B3q9njFjxhAQEEBgYCBnzpwpVmb+/Pn4+/vTp08fs+H1Oyn1yUH37t1ZvXo1\nAwcOpFmzZmRnZ5u+7YeGhvLZZ58RGBhIRkYGbdu2JTQ0lK+++org4GDi4uIIDQ29Y93BwcGkpqYS\nHBzM3LlzmTBhgrVuSwghhIMwGhWLjwfx9ddf4+bmRmxsLO+88w5z5841O5+WlkZycjLr168nNjaW\nuLg4srOz71pnqX9aoVmzZnz77bemn1966SXTn11cXFizZo1ZeXd3dz799NNi9dzsIQBYuHDhbf98\nu7JCCCEebX8fvi5pu3fvpkePHgA899xzhIeHm52vWLEiN27coKCgAIPBgFarpXz58nets9QnB0II\nIYQtqT3R8MKFC1StWhUArVaLRqOhoKAAnU4HQK1atXj11Vfp2LEjBoOB4cOH4+rqetc6JTkQQggh\nVFSS6xx8/vnnfP7552avHTp0yOznv/dUnDlzhu+//55t27ZRWFiIv78/vr6+VKtW7Y5xJDkQQggh\nVGQsLCixuvz8/PDz8zN7LSwsjOzsbLy9vdHr9SiKYuo1ADhy5AjNmzc3DSU89dRTpKWl8eyzz94x\nTqmfkCiEEELYkmI0WHw8iHbt2hEfHw9AYmJisf19PDw8SElJwWg0otfrSUtLM638eyfScyCEEEKo\nSDE82Ie+pXx9fdm1axcBAQHodDpmzZoFwPLly2ndujUtW7akXbt29O3bF4BevXpRt27du9apUdSe\nRinu6I+LeVaPeemGur+kd+JVuazVY+Zct829Zl/V37uQCryrONsk7m+XbfM+H79wfzurloSuNW9Y\nPSaAUvbuk8fUcnXDPJvEDRu6ziZx/638rkq9dfuttLhsRswgVdpwv6TnQAghhFDRgw4X2JIkB0II\nIYSKJDkQQgghhJmSfFrBWiQ5EEIIIVRkdMCeA3mU8T506tSJ/Px8li9fzoEDBwBISEiwcauEEELY\nM7UfZVSDJAcPYMiQIbRs2ZKMjAy2bt1q6+YIIYSwY5Ic2Lm8vDzeeustAgICWLBgAZ06dTL1BgDM\nnj2buLg48vLyGDp0KEFBQfj5+XH48GGzesLCwkhMTCQiIoK9e/eyePFifHx8TPXs27ePkJAQq9+f\nEEII+6MYDBYf9uKRSg42bdpEw4YNiY2N5R//+Mcdy2VnZ+Pn50dUVBTvvvvuHfe+HjRoEG3atCEk\nJISXX36ZH374AYDt27fTtWtXVe5BCCGEYzEWFlh82ItHKjlIT0+nefPmALRp0+aO5apXr05CQgIB\nAQHMmTOH3Nzce9bdvXt3vvnmGwD27t1Lx44dS6bRQgghHJoMK9g5RVHQaDQAODk5FTuv1xetbBcZ\nGYm7uzuxsbFMnTrVorq9vb25cOEChw8fpn79+pQta/0VAYUQQtgfxWi0+LAXj1Ry8OSTT5q2tty9\nezcArq6uZGdnYzAYTOdycnLw8PAAYNu2baak4e+0Wi2FhYWmn1977TUiIiLo1q2bmrchhBDCgUjP\ngZ3r3r07R44coV+/fhw/fhyAwMBA3nnnHUJCQkzzELp3787q1asZOHAgzZo1Izs7m40bNxarz8vL\ni6NHj/LBBx8ARZtf/PnnnzzzzDPWuykhhBB2zRGTg0d246X8/Hy6detmmkRYEjZu3EhmZiahoaEW\nlZeNl9QlGy9Zh2y8pD7ZeMk61Np4yeX50RaXzd85X5U23C9ZIbGETJw4kTNnzvDJJ5/YuilCCCHs\niFFvP08hWOqRTQ5cXFxKtNdgxowZJVaXEEKI0sOehgss9cgmB0IIIYQ1OGJy8MjOORBCCCHE7T1S\nTysIIYQQ4t4kORBCCCGEGUkOhBBCCGFGkgMhhBBCmJHkQAghhBBmJDkQQgghhBlJDoQQQghhRpID\nB5GWlvZIxLSlo0eP2roJQghhF2QRJAcxcOBAcnNzefXVV+natSu1a9cudTGfeeYZNBoNALm5uZQr\nVw6j0UhBQQHu7u78+OOPqsYPDg5m1apVlCnzaCwc+ueff5KRkcHTTz9NQUEBOp1O9ZhpaWnMmjWL\n/Px8NmzYwJo1a2jdujWNGzdWNe7s2bPp2rWr6nGEKC0kOXAgeXl5/Oc//yExMZErV67QsWNHunbt\niqureju22SLmjBkzeP3112nWrBkA+/fv55tvvmHixImqxQR45513SEtLw9vbG2fn/+1wuGDBAlXj\nnj17luzsbJo1a8amTZtISUkhICCAJ598UrWYa9asIT4+nqtXr7J582bef/99atSowZAhQ1SLCRAU\nFMTUqVOZOnUqUVFRnDx5kkmTJhEbG6tq3C1btrB9+3YyMzPp0KEDr7/+OvXq1VMt3q2J7q0URUGj\n0bB7927VYkPR/7fZ2dl4enqyd+9ejh49yuuvv07VqlVViXfr/f79I0Xt+x0xYgTdunWjQ4cOVklw\nHxmKcChHjx5V5s6dq/j7+ysTJkxQevXqpWzZsqVUxezTp0+x1wIDA1WLd1NycnKxY+vWrarH7dev\nn3L06FHlwIEDSlBQkPLLL78oAwcOVD2movzvfTUajUrv3r1VjakoivLWW2+ZxVUURenbt6/qcW8q\nKChQduzYofTq1Uvp3bu3EhcXpxiNRlVjWuN39+8GDRqk7NmzR0lLS1N69uypbNq0SRkyZIjV22EN\n+/btUz788EOlV69eyvjx45Vdu3bZukmlwqPRf1oKLFiwgG3btuHp6Un37t0ZMWIEzs7O3Lhxg969\ne9O1a9dSERPA3d2dESNG0LJlS7RaLUeOHMHNzU2VWLdq1aoVO3fuJDc3FwC9Xs+yZcvw9fVVNa6T\nkxMNGzZk9uzZ9O/fn3/+858YDOpu1HKz/pvf9m7cuEFhYaGqMQEqVqzIF198wbVr1zh06BDff/89\n1apVUz0uwMGDB9m6dSt79+6ldevWvPbaa+zatYtRo0ap2jt0ux4EtRUUFNC2bVsWLlzIW2+9Rbdu\n3YiLi1M97rFjx/jggw/4448/MBgMNGjQgAkTJuDl5aVazFatWtGqVSsAjhw5QkREBOfOnaN3794M\nHDiQChUqqBa7NJPkwEGUKVOG6OhoKlWqZHotPT0dLy8vIiIiSk1MgHnz5rFz507S09MxGAx06dKF\n9u3bqxbvplGjRuHi4sLevXvp1KkTycnJhISEqB7XYDCwdOlSfvjhB0aNGsXhw4fJz89XNWbXrl0J\nDg7m9OnTTJkyheTkZIKDg1WNCTBz5kwiIyOpUqUKy5cvp3nz5sycOVP1uJ07d8bb25vu3bszbtw4\n07ySf/7znwwdOlT1+NZWUFDA5s2b2bp1Kxs3biQjI4MrV66oHnfGjBmMHz+eJk2aAEUJ2bRp01i7\ndq1qMa9du8YPP/zAN998w4ULF/D19cXX15ekpCSGDx/O6tWrVYtdmsmcAzt38eJF/vrrL8LDw5k1\na5ZpPK+wsJCRI0eSkJBQKmICbNu2DR8fH2JiYm57vl+/fqrEvSkoKIioqCjTfy9fvsyUKVOYP3++\nqnHPnj1LQkIC7dq1o379+nzzzTc88cQTNGrUSNW4GRkZHD58GJ1OR+PGjalVq5ZqsX7++ee7nm/d\nurVqsQE+/fRT3n77bbPXVq9ezYABA1SJ95///AcoGn+fO3cuY8eONTv/4osvqhL3pmPHjrFx40Ze\neuklnn32WWJiYvDw8OCFF15QNW5wcHCxRKB///5ERkaqFvPll1/m5Zdfpnv37jz11FNm5yZNmsT0\n6dNVi12aSc+Bnfvtt9/YuHEjv//+O1OnTjW9rtVq6datW6mJCZi+2eTk5KgW4270ej2ZmZk4OTlx\n6tQpatWqxalTp1SPW6tWLZo1a0ZaWhr169fn6aefpmbNmqrEGj9+/G1f3759O4Bq3+KjoqIAuHz5\nMmlpaTRp0gSDwUBqairNmjVTLTlISkpi586dxMfHc/HiRdPrhYWFfPvtt6olB/Hx8aY/N27cmHXr\n1qHRaKhcuTIajUb15KBhw4YMGjSIzMxMAPz8/KwyWc/NzY1PP/2UNm3aALBnzx6znkc1dO/evVgP\n36xZswgLC5PE4CFIz9TdHcgAAB+2SURBVIGD2LVrF88991ypjwlw9epVdu/ezUsvvQTAV199xSuv\nvKL62OHu3bu5dOkSVatWJTw8nLy8PPr27UtoaKiqcWfPns3Zs2f5448/iIuLY9GiRVy6dEmVpzNu\nPg76ww8/oNVqadOmDYqikJycjE6nU/2JkOHDh/Phhx/i4uICFM2qnzhxIh9//LEq8fLy8khNTWX6\n9OkMGjTI9LpGo6Fx48bUr19flbg3xcXF8fHHH1OpUiUURSE/P5/Ro0fz+uuvqxrXVk+j5OXlERkZ\nSUpKClqtlqZNmxIUFGT6+y5J3333HV9//TW//PKLWXJZWFjIsWPH+OGHH0o85qNEkgM7N2XKFKZN\nm8abb75524lNX3zxRamIeat33nmHZ599lv79+wOwYcMGfvzxR5YuXapqXFv5+3AGQN++fVm3bp1q\nMQcMGFBsLHbo0KEsW7ZMtZgAb7zxBp999pnpUdHCwkL69OnDxo0bVYmXmZlJnTp1OHHixG1/l//x\nj3+oEvem7t27s2bNGqpUqQIUDdkNGDCATZs2qRo3MDCQ6Oho0++Uoij4+/uzYcMGVeMC/Prrr1y5\ncsX02CaoN2yUkZFRLPHTarU8+eSTqj22+aiQYQU7N2LECAAWLlxYqmPe6sqVK6bEAKBPnz58/fXX\nqsd98cUXyc7OxsnJCY1Gg8FgoHLlylSqVInw8HCef/55VeIWFhai1+tN/5BevHiRGzduqBLrptzc\nXBITE2nRooXpiZA///xT1ZgAvr6+dO7cmQYNGgBw6tQpunfvrlq8tWvXMn78eCIiItBoNGbP4Gs0\nGlUnykHRkzeVK1c2/VylShU8PDxUjQm2exrlnXfeITc3F3d3d9N7rdFoVEkODh06RPPmzQkICODa\ntWtm544cOaL60E1pJ8mBnZs7d+5dz6sxRmyLmLdydXUlOjqaVq1aYTQa2bNnDxUrVlQ1JsBrr73G\nM888Y/pHZefOnezfvx9/f39GjBihWnIwYMAA+vTpQ1ZWFm+//Ta//fbbHecGlJTZs2ezZMkS5s2b\nh6IoPPnkk1Z5amDw4MH4+/tz+vRpFEXBw8ND1THp/2/v3sNqTNc/gH/XSqdRbAyhMo5JE4pNDj+T\njb0ZRRlG2elgGjYGU1eoNIbkUA11aSqDRCdcsx3KrhymMsweKqKdKIfSNJQKlVYZtdbq90fXener\nNLPNeN631bo//+zWWtflfqZdvff7Pvdz34rvY1xcHF69egVtbW3U1NSgrKwMo0aNYhZXQU9PD3Z2\ndpg4cSLkcjlyc3NhaGiI4OBgAMDGjRuZxH3daZTWCTcr1dXVvDydAICsrCyMHTu2wwJpSg7+GNpW\n6OSE2CMWel+6rq4Ohw4dwp07dyAWizFmzBi4uLgw7coIAI6Ojjh+/LjSe05OTkhISICDgwPTP3oN\nDQ148OABtLS0MHjwYOjo6DCJo2iTrLjTan13BwC6urpM4oaHh2PNmjVYt27dax/vs+5CGRAQAHNz\nc1hbW8PV1RUWFhYQiURMj+QCwOnTp3/18wULFjCJK5VK8eTJE6XTKLq6ukpPMVj4+uuvMWfOHOa1\nHADaPS1oi9XPsrqg5EBFCLFHLNS+NADU19ejtrYWQMsFbdu2bYiOjmYa08PDA01NTRg3bhz3qF0i\nkWDRokU4e/bsWz/S6Ozs/KsNclg88vby8sKePXswY8YMpdiK/WHFqYW3rbCwEKampsjOzm73GavH\nzq0pkryYmBg0NzfDzc3ttT/fqk4qlaKxsRErVqxAVFQUl/zJZDIsWbIE//rXv5jEVbRPbm5uRm1t\nLfT09KChoQGAXfvktj/DCqx/ltUFbSuoCCH2iIXalw4PD8fp06dRU1ODgQMHoqysDA4ODszj7t69\nGz/88APXfGnOnDmYPn06Xr58iRkzZrz1eF9++SUA4Ntvv0W/fv1gZWUFuVyOrKwsvHjx4q3HA/67\nZZSUlNRuq6asrIxJTAAwNTUFAKSmpmL9+vXcU6DHjx8jICCAeXLQ2NiIiooKnDlzBhEREZBKpcy+\nx0K6fPkyDh8+jLy8PNjY2HDJgeIJICuZmZnM/u2O/NppBD66QXZ19ORARdy7dw+RkZEoKiri9ohX\nrlzJtFGOEDEBcI/wFZXWt2/fxrlz5+Dl5cU0bnh4+GvfZ90l8XWNYz799FNERUUxizlv3jysWrUK\nc+fOhUwmQ3R0NFJTU3/zMfgflZSUhLi4OLi6uqK8vJzrCjlp0iSmcRMTExEdHQ1bW1usWLECoaGh\n6N69O/OjfUJJSkpqV+jJx9Hkx48fIzw8nNsSNDc3x9q1a5n17QBaig8PHjyo1Pb86dOn+O6775jF\nVAeUHHRyQuwRC7UvreDo6Ihjx47ByckJ0dHR0NHRYX60D4BSZ8ampibcuHEDBgYG8PPzYxrX0dER\nNjY2SrMkTp48iW+//ZZZzBcvXmDfvn0oLi5GXV0dZs2aBWdnZ6VplKzcuXMH7u7uXOGpgYEB85jq\n5ueff8bRo0eVLpjXrl3jOjey4ubmhiVLlsDKygpNTU3Izs5GYmIiDh48yCymg4MDPD09sXv3bmzd\nuhXfffcdLCws8Je//IVZTHVA2wqdnK+vL/bs2QMbGxve9oiFiNna7NmzERMTg3nz5sHOzg59+vTh\npbiobXtmNzc3rFy5knncvXv3IjY2FuHh4dwTGlZNgRQ0NTWhra0NqVQKkUgEbW1tbo+YpYCAAJSU\nlCA+Ph7V1dX4/PPPMWPGDOZ38BEREYiPj+deK36WWY9OFoqPjw8++ugjxMTE4LPPPkN6ejrz4kug\npbZh9uzZ3GsbGxumSS4A6OjoYNKkSdDS0oK5uTnMzc3h7u5OycEfRMlBJ6fYI87IyOCOYgEtFf2s\njvcJEbO11i1tra2tUV1dzcuxswcPHii9rqqqYto+WdGgp66url3VekNDA7O4QMvd1ieffAIPDw9I\npVJER0fD0dGR+R/yMWPGYPPmzdzrhIQEHDlyhGlMADh//jzS09PVZkJft27dsHDhQpw+fRqzZ8/G\n7NmzsXz5cubH+7S0tHD27FlYWVmhubkZmZmZzNs26+rqIj09HUZGRggJCYGxsTHKy8uZxlQHtK2g\nImJjY3HlyhV88803AFqajUyZMoXpJD0hYgrJ2dmZ+1okEkFfXx+LFy9m9gd1165d8PX1bXdqQXFX\ny7JBT21tLXr27IkXL15ALBZDT08PZWVlGDhwILOYirhxcXFKe9Ks2uu25uHhgeDgYF7mC3QGLi4u\nWLNmDWJjYzFt2jQMGjQI27Ztw9mzZ5nGraiowN69e5XaJ7OuOZBIJHj27Bn69OmDI0eOoKamBvb2\n9txkSPL7UHKgIhwdHXH06FGIxWIALReQJUuWtDuXr+oxhda6UU55eTkvTyxOnDiBRYsWMY/T2pUr\nV+Dv7w9tbW00NjZCQ0MD27Ztw/jx45nGXbVqFSZMmKC0J52fn8+8G+e6deuQn58PMzMzpe0T1v0V\nhFJRUYHKykr07dsXe/fuRU1NDRwdHZk/OWhubsatW7cwZswYAC3zShTHHFlJTEx87fv29vbMYqoD\n2lZQEYqjV4omJlVVVV0ypkJ5eTk3Qri4uBhDhw5lHlOoRjlXrlyBpaUlhg0bxjROa2FhYYiLi+Pu\n6MrLy+Hl5cW86LO+vh6ffPIJ99rCwgJubm5MYwItswbUiYGBAaqrq/Ho0SN89NFHSnMOWPL29ka/\nfv245ODatWtITExEUFAQs5h3797lvpZKpfjPf/6DESNGUHLwB1FyoCI8PT3h4OAAbW1tyOVyyOVy\nbNmypcvFBIDg4GA8f/4cgYGBAIBDhw6hZ8+ezFrNKhQWFmLz5s2IiYnBwoULuUY5rOXn52PevHnQ\n1dXlTguwLpbT1NRUetQ7YMAAdOvG/s+BXC7HrVu3MHr0aAAt/fHlcjnzuOPGjcO5c+dQUVEBd3d3\n3Lt3D0OGDGEeVyiKGQet/z/mo9lUWVkZ1xoaaHli03q7jgVvb2+l1zKZjPkkVXVAyYGKmDp1Ks6f\nP4/nz59DLBbjT3/6E/Mz6ULEBIDc3FylO9gdO3a0O0nAglCNci5cuMA8RltGRkbw9/fnWmNnZmby\nMhBo8+bN2LlzJ4qKigAAJiYmvCScmzdvRu/evZGdnQ13d3dkZ2fjm2++QUhICPPYQuBzxkFrIpEI\n33//PSwtLbm5KKyTzrZtlCsrK1FcXMw0pjqg5EBFdNTog1VvdqFiAi13l/fv3+f6s+fl5YGP0hgn\nJycsX74ctra26N+/P0JDQ5WOZbFSUFCAnTt3orS0FDKZDCYmJvDz82O6zRAQEIDk5GTk5ORwd5Rz\n585lFk9h5MiRiImJYR6nrfLycuzatYu7i126dCnOnTvH+zr48n//939Kv0N8CQoKQmhoKL766itu\nLgrrgV62trbc1yKRCHp6ekpbV+T3oYJEFSFEow+hmovcuXMHO3bswMOHDyEWizF8+HBs2rSJG/PL\nF772aZ2cnODr68tVV+fm5iIkJITJaQXFmNuOmuGwKlj77LPPEBER0a44ja9+A05OTti3bx9XwV9U\nVARfX1/mRzf5JsSMA6D93TufjdNmzpzZ7uZB8T2gGQu/Hz05UBFCNPoQqrmImZmZUrdCofCRGACA\nhoaG0rErRSEkC4oxtx3dNbNKDiIiIgAI04MfaKmfcXNzQ0lJCT788EMALdtVXY1Q39+2DdPaYnmB\ntrOzw/DhwzFx4kRoaGjg6tWruHv3Lv7xj38wi6kOKDlQEUI0+uA7Zkd3lwpdtZtdjx49EBUVxQ3G\nyczMRM+ePZnEsrW1RVlZGdauXcvk3++IEBMoAeXJfc3NzZDJZKiqqkKPHj2wceNGpKWlMYkrtMLC\nQkRERODhw4cQiUQYNmwY1qxZg+HDhzOJpxiClJeXh6ioKFRXVwP471YkS1lZWUoFiHPnzsWxY8fU\npuEVK7StoCIkEgmePn2Kd999l2v0YWdnx1V9d5WYAHD79m28//77TGO01rYzYlus/qAqSCQSxMTE\nID8/HyKRCGPGjGHWGGjhwoUQiURoamrCw4cPYWxsDJlMhsePH8PMzIxZEdv9+/cBdDyBcsOGDUzi\nNjQ0oLm5Gfv374epqalS3JKSEuZDtYSyYMECrFu3DhYWFmhubsbNmzfx9ddfd9gT4G1RbEXu2bMH\nW7Zs4WUrctmyZRg1ahT3xC03Nxe3bt1i2kRMHVByQDodFxcXREdH83K0DsCvHrVi2alQyKRkw4YN\n8PLyQv/+/QG0tHIOCwtjeh4dEGYCJdBSgNh6tgLQclE5fPgw07hCed1/28qVK7lup6y4uroiJiZG\naVCau7s7Dh06xCymRCJBUlISiouLudkkdnZ2vLR678poW4F0Orq6uvjb3/4GU1NTpSmBrLrZxcXF\ndfiZYq+cBX9//w4/Y90+uaSkhEsMAMDQ0BA//fQTs3gKjY2NiIuLU5pAycdxUS0tLQQGBirFlclk\nzOMKZejQodi6dSumTJkCuVyO69evo1+/flwhKqvaEiG2P/X09Hg56qxu6MkB6XSys7PbvcdHA5dL\nly5h7969qK2tBdCyX9q/f/8uV9EOANu3b0dubi7Gjh0LkUiE27dvw8TE5FcTlrehoqKCOy2guMtz\ndnZmPtNBIpHgzJkzXNwhQ4bA3t6+y95d+vr6/urnrI4XCrUVSd4+Sg46OaF+yYGWX/T4+Hg8e/YM\nfn5+yMzMhJmZGXr06MEsJtDSVa1tr/3Fixczv0gvWrQIoaGh8PHxQXh4OC5cuIDu3bsrnaNmITIy\nEvHx8e2OY7EuwCwqKsKDBw+4i+XIkSOZxiPstT1S2BYfo89J10DbCp2coglPRkYGxGIx19EuKyuL\n+YQ5Hx8fTJkyBd9//z0A4Pnz5/Dy8sLBgweZxDt//jwOHDiAu3fvYvLkydzFsrm5mZcBSLq6ujA2\nNoZcLkevXr3g4OCAZcuWMU8Ozp49i7S0NN6rq4cNG8brPAfCnuJIYetEk878k9+DkoNObvr06QCA\nmJgYpQIjGxsb5ud46+vr8fe//50b86o4IsSKYu78oUOH4O7uzixORwwMDJCYmAgzMzOsX78eRkZG\nePbsGfO4pqamvBVfCo2vxlLqSnGkkJA/Sj3+InUBNTU1uHjxIiwsLCAWi5Gfn48nT54wjSmXy1Fa\nWsr9Mb98+TLTITnHjx+Ho6Mjnj59qjS8RYH14KWgoCDU1tbC1tYWycnJqKmpYVrdvW7dOohEItTX\n12POnDm8jhO+dOkS8/G9r+Ps7Nzu1AB5+1r3d1DQ0NAQZI4HUU2UHKiIoKAgREZGIiQkhCvkYt2z\nfPPmzfjyyy+Rn5+PqVOnwtTUlOn4YkNDQwDgvU2ywr59+9q9d+rUKWZn4RVjhCsqKiCRSLhH/Ddv\n3uS+F6zEx8fD0tKSef1IW4aGhvDy8sLo0aOVTqJQtfnblZyczH0tlUpx/fp1PHz4UMAVEVVDyYGK\nMDExQXBwMCoqKmBsbMxLzOHDh+PIkSO8xAKAadOmAQCmTJmCixcvwtHREQCwf/9+5sOeAKBXr17c\n101NTbhx4wYMDAyYxVN0RFy2bBk+/vhj7nVDQwNiY2OZ1jpIJBJYW1tj0KBB0NTU5B73nzhxgllM\nANzPrkQiYRpH3bWtX5kxYwZcXFwE2a4jqomSAxWRkpLC3dkmJydj+/btMDc3h729/VuP1Xp4ixBD\ncnx8fPDxxx9zr0eOHAkfHx9ER0czjdv27tXNzQ0rV65kGhMAfvnlF6WJiNOnT2faNAYAdu/ezfTf\n74iVlZUgcdVNUFCQ0u9uVVUV6uvrBVwRUTWUHKiIhIQEnDp1isv8N2zYAGdnZybJgVDDWxSEuFgC\n7TsWVlVV8fIoduDAgQgKCsK4ceMgl8uRmZnJ/Nx/eHj4a99nvVXVuuGUVCpFQUEBzM3NmfewUDfd\nu3eHlpYW+vbtC5FIhB9++EGwhJCoJkoOVISGhga0tLS4uwGWxxjDw8OxZs0armCuLZaFcoAwF0tA\nuWOhYi78pk2bmMcNCgrC6dOnceXKFWhoaGDs2LGwsbFhGlNxRBZouUjn5OQo1QCw0rZ/xcuXL+Hn\n58c8rrrJzMyEn58fXr16hZCQEGzduhXBwcG8JNmka6DkQEWMGzcOGzZsQEVFBQ4cOICMjAxMnjyZ\nSaxZs2YB+G/BXGt8HEMT4mIJ/HobZZa6deumtI3CB8URWYVZs2Zh+fLlvK4BAMRi8W/OmCBvTkND\nA6NGjUJQUBBcXV0xfvx4SKVSoZdFVAglByrC09MT169fh4mJCTQ1NeHt7Q1LS0smsUxNTQG0VLQL\n0amQ74tl6xHRNTU10NHRgVwuR2NjI/r374+LFy/ytha+KHrsK1RWVuLnn39mHrd1PQvQkhwoCk/J\n2yOTybBv3z5kZGTAw8MDeXl5aGhoEHpZRIVQ+2QVsXXrVqxfvx56enoAWqboBQQEMDmH37pTob6+\nvlKnQjMzsy47yW779u2YP38+xowZAwC4ceMGUlNT8cUXXwi8srevbVtuPT092NnZwdzcnEm8nJwc\njB8/HteuXaP6Ah6Ul5fj/PnzmDp1KkaMGIHU1FQMHjwYZmZmQi+NqAhKDlREUlIS4uLi4OrqivLy\ncu6OYNKkScxivq5T4d27d7tsD35HR0ccP35c6T1nZ2fBthtYCA0NhaenJ/e/fPnwww+xfv167N27\nF15eXu0+F6IhEyGkY7StoCLs7OwwYsQIuLu7Q09PD/Hx8UzP4AMtg4gSEhJQXV0NoOXsf2JiYrtH\n0l2FgYEB1q5dqzTWl+8mQaylp6ejqKgIN27cQElJSbvPWRWbrl69Gunp6Xj+/DnOnTvX7nNKDgjp\nXOjJgYoICAhASUkJNm3ahOrqauzevRszZszAihUrmMVctmwZLC0tkZKSAgcHB1y6dAnOzs5cwWJX\nI5PJ8O9//1tprO8HH3zQpeYeVFdX48GDB9i1axd8fHzafa5oxMTK1atXmRXSEkLeHkoOVERSUhLs\n7Oy41zKZDEeOHGHa8czV1RUxMTHco/XGxkZ4eHggMjKSWUwhpKWlYdasWUhISHjt512pte9vnQwY\nPnw4k7gLFy58bWMtBdadGQkhb6br3BJ1UYoLl0QiaXfx0tHRYRq7qakJhYWF0NHRwY8//ghjY2OU\nlpYyjSmEuro6AOC2T7oyf3//diN9FUQiEWJjY5nEbXvqhRDSudGTg04uMTER9vb2HXa0YzUUCAAK\nCwvx/Plz9OnTBzt27EBNTQ2WLl2KxYsXM4sppLq6OlRVVWHo0KHIyspCQUEB5s+fj969ewu9tC6j\n7SkJBdadGQkhb4aeHHRyWVlZsLe3R1lZGXbu3MlLzJcvXwIA3nvvPbz33nsAWoYfdfRIuKvw9PTE\n8uXLIZPJEBwcDFdXV/j6+mL//v1CL+2ta93bQSqVor6+HkZGRsxH+grVmZEQ8mYoOejkioqKsGDB\nApSWluLevXvtPmexV2tjY9Pu0XPr/eL09PS3HrMzaGxshJWVFcLCwuDm5oZ58+bh1KlTQi+Libbz\nMwoLC3HmzBnmcTtLZ0ZCyK+j5KCTO3r0KCorKxEYGAhvb29eYmZkZCi9rq2thVgshr6+Pi/xhdLY\n2IgzZ84gJSUFJ0+exKNHj7h6hK7O1NRUabYEK0J1ZiSEvBmqOSAdunLlCvz9/aGtrY2mpiaIxWJs\n27YN48ePF3ppTBQUFODkyZOYOXMmJk+ejISEBAwaNAjTpk0TemlvXduhWpWVlXjnnXeYD+ZpW3Og\nr6+P+fPnM+vMSAj5fSg5IB1ydHREWFgY+vXrB6ClJauXlxeOHj0q8MrYKS8vx+PHj/HnP/8ZjY2N\nTKdfCik7O5v7WiQSQV9fHyNHjmReUyKVSlFTU4N3330XxcXFKC4uxrRp06Ctrc00LiHkzYiFXgDp\nvDQ1NbnEAAAGDBjQpRoCtXXkyBF4enpi27ZtAICvvvoKBw4cEHhVbOjr66OxsRETJ05EdnY2wsLC\ncPPmTeZxN2zYgNzcXDx69Aiff/457t+/z9t2GSHkf0fJAemQkZER/P39cfbsWaSmpmLLli0YNGiQ\n0MtiJi0tDcePH0fPnj0BAJs2beqyxZf+/v4YPHgwfvzxRxQWFmLLli289CJ4+vQpZs2ahdTUVDg7\nO2PVqlWora1lHpcQ8ma67m0g+cMCAgKQnJyMnJwciEQijB8/HjY2NkIvixmZTAYA3KP1V69eQSqV\nCrkkZrS0tGBkZISoqCgsWbIEBgYGkMvlzOP+8ssvyMnJwZkzZxAbG4sXL15QckBIJ0TJAenQ4sWL\nMWfOHDg7O3P9DroyW1tbuLi44KeffsKWLVuQlZUFV1dXoZfFhKamJr744gvk5uZi8+bNuHz5Mi+J\nkIeHB6KiorBixQr07t0bkZGRcHFxYR6XEPJmqCCRdKisrAzp6elIT09HXV0dZs6cidmzZ2PYsGFC\nL42JyspKNDY2Ii8vD1paWnj//fcxYMAAoZfFhEQiwdWrV2FhYYG+ffvi6tWrGDRoEAwNDYVeGiGk\nE6DkgPxPnjx5gtDQUKSkpCA/P1/o5TCxdOlSxMfHC70MQggRHG0rkA49efIEGRkZuHjxIiorK2Ft\nbY1jx44JvSxm+vbtC0dHR4wePVqppe/GjRsFXBUhhPCPkgPSodWrV+Ovf/0rvL29mY3y7Uw++OAD\noZfQZbXtjNiWtbU1TyshhPwvaFuBEDX05MkTREREoLa2FmFhYUhJSYGFhQWzmoOOpjEq0FRGQjoX\nenJAiBry8/ODi4sLDh48CADo3bs3fHx8EBcXxyReRxf/pqYmXmY6EELeDDVBIkQNyeVyWFtbcz0d\nJk+eDD4eIp44cQLTpk2Dubk5xo0bhwkTJkAikTCPSwh5M5QcEKKGunXrhqtXr0Iul+Pp06c4duwY\nL/MNjh8/jrS0NFhaWuLGjRvYs2cPLC0tmcclhLwZSg4IUUM7duxAcnIyqqur8emnn6KgoICXfX9t\nbW1uyqdcLsfMmTORlpbGPC4h5M1QQSIhaqqxsRGVlZUwMjLiLWZgYCCMjIxQU1ODrKws9O/fHyUl\nJfjnP//J2xoIIb+NkgNC1FBKSgr27dsHAEhOTsb27dthbm4Oe3t7pnGlUinkcjm0tLRw7do1VFdX\nY/To0V22EyUhqoq2FQhRQwkJCTh16hR69eoFoGWU8tGjR5nFk0qlaGhogJubG+RyOV6+fAlzc3NM\nnjwZK1asYBaXEPL70FFGQtSQhoYGtLS0uNMKWlpaTONdvnwZhw8fRl5eHubOncu9LxaLMXHiRKax\nCSFvjrYVCFFDoaGhKCsrQ15eHhYuXIiLFy/CysoKHh4eTOMmJSXBzs6OaQxCyB9HyQEhaqi5uRk5\nOTm4efMmNDU1MXbsWF6OFN65cwe7du1CaWkpZDIZTExM4Ofn12UnfRKiqig5IEQNCTWB0snJCb6+\nvjA3NwcA5ObmIiQkBLGxsbyvhRDSMao5IEQNGRoawsvLq90ESicnJ6ZxNTQ0uMQAACwsLLi6B0JI\n50HJASFqyNjYGAB4b13co0cPREVFcUWImZmZ6NmzJ69rIIT8NtpWIESN+Pr6YteuXdi0aRN27tzJ\ne3yJRIKYmBjk5+dDJBJh9OjRcHV1xTvvvMP7WgghHaPkgBA1snjxYjQ1NaG0tBRDhgxp9/mJEyeY\nxo+MjMTq1auV3gsMDISPjw/TuISQN0PJASFqRCqVorKyEoGBgfD29m73uaGhIZO4Fy5cQHJyMq5f\nv44JEyYoraegoAAZGRlM4hJCfh9KDgghvHj06BECAgLg7u7OvScWizF06FD07t1bwJURQtqi5IAQ\nQgghSmi2AiGEEEKUUHJACCGEECWUHBBCCCFECSUHhBBCCFFCyQEhhBBClPw/iGAPqeJvmPQAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9a0215780>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 4)\n",
    "\n",
    "ax=sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TXVlJTFSPd4X",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231.0
    },
    "outputId": "d37993c9-d4a2-4acf-9ae3-bea76b4fb719",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.544347160014E12,
     "user_tz": -330.0,
     "elapsed": 1018.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e44ce5aab52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mquant25\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mquant75\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Index' object has no attribute 'quantile'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for columns in train:\n",
    "  quant25=train.columns.quantile(.25)\n",
    "  quant75=train.columns.quantile(.75)\n",
    "  for i in range(len(train.columns)):\n",
    "    if train.iloc[i]>quantile(.75):\n",
    "      train.iloc[i]=train.columns.median()\n",
    "    elif train.iloc[i]<quantile(.25):\n",
    "         train.iloc[i]=train.columns.median()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7w6vW1kVoQEP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "y=train['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "T9ghfAVxoQIe",
    "colab_type": "code",
    "outputId": "b5049e89-5942-4915-d84a-ede312cf3118",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347758867E12,
     "user_tz": -330.0,
     "elapsed": 584.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "23TJRVuDoQMz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9YeZZhG0hrKx",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163.0
    },
    "outputId": "97bae292-3e37-46f3-ae34-8128f65980fa",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.544347760179E12,
     "user_tz": -330.0,
     "elapsed": 703.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1e646152d001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train2' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vHszg8fvhiNt",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "x2=train.drop(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',\n",
    "       'pH', 'sulphates','quality'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1_Z5KM29g-Ny",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163.0
    },
    "outputId": "9a30f466-0702-4cf8-cb19-056bcf870023",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.544347767006E12,
     "user_tz": -330.0,
     "elapsed": 1149.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-04d7f189627d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train2' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ReBKbdchoQQs",
    "colab_type": "code",
    "outputId": "c6ed02cf-23f1-408c-ab84-049a16a7dfba",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347767967E12,
     "user_tz": -330.0,
     "elapsed": 1033.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0010</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9940</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9951</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9956</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9956</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   density  alcohol\n",
       "0   1.0010      8.8\n",
       "1   0.9940      9.5\n",
       "2   0.9951     10.1\n",
       "3   0.9956      9.9\n",
       "4   0.9956      9.9"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "008-n4Omij3r",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "d6dc68f5-37cf-4220-820c-f32f82424708",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347774284E12,
     "user_tz": -330.0,
     "elapsed": 1145.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gaR-Z9zyoQVH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x2,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SaoeE9pOnkQf",
    "colab_type": "code",
    "outputId": "257fa237-9881-48b2-ede4-40950ef3dcc0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347776061E12,
     "user_tz": -330.0,
     "elapsed": 954.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>0.98961</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>0.99242</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>0.99472</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>0.98968</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>0.99044</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      density  alcohol\n",
       "4554  0.98961     12.7\n",
       "3401  0.99242     11.2\n",
       "3330  0.99472     10.1\n",
       "4462  0.98968     13.4\n",
       "3171  0.99044     12.0"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "b2F0PENfnkTe",
    "colab_type": "code",
    "outputId": "6a3ba03a-6d80-4036-a5da-c478fee10f45",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347792502E12,
     "user_tz": -330.0,
     "elapsed": 1127.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uCzK4aV7nkWp",
    "colab_type": "code",
    "outputId": "8e67f271-1e3a-4074-e258-8f5b8cfb1ab2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347793582E12,
     "user_tz": -330.0,
     "elapsed": 1128.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>0.99773</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>0.99560</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>0.99210</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.99610</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.99036</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      density  alcohol\n",
       "2414  0.99773      9.2\n",
       "1584  0.99560      9.2\n",
       "3248  0.99210     11.1\n",
       "645   0.99610      9.0\n",
       "3163  0.99036     12.7"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YYitkBYsnkaO",
    "colab_type": "code",
    "outputId": "983dea5e-9b0e-49db-8d02-daaf1324d050",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347798704E12,
     "user_tz": -330.0,
     "elapsed": 955.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VUKcIpbMowb-",
    "colab_type": "code",
    "outputId": "4fd3cdb3-3e8f-42e8-e2ca-9c493a59b735",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544347800617E12,
     "user_tz": -330.0,
     "elapsed": 1572.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4554    6\n",
       "3401    5\n",
       "3330    6\n",
       "4462    6\n",
       "3171    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5Mwz-8klowf-",
    "colab_type": "code",
    "outputId": "cd06a681-ba74-47bd-ec6e-286792c9cf01",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54434780062E12,
     "user_tz": -330.0,
     "elapsed": 556.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428,)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vbJ_sn5Iowjd",
    "colab_type": "code",
    "outputId": "0a291ad9-8863-4379-bf83-3e3e82924f8b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348260637E12,
     "user_tz": -330.0,
     "elapsed": 880.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470,)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "UtBN-UkzownB",
    "colab_type": "code",
    "outputId": "84c89581-5480-40e8-bab7-c88c6f77cebf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348261764E12,
     "user_tz": -330.0,
     "elapsed": 1017.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(random_state=1)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NfElYnzsowqT",
    "colab_type": "code",
    "outputId": "d9a3c1ea-e917-4c3e-bdc9-77dd83beb902",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348269472E12,
     "user_tz": -330.0,
     "elapsed": 807.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859393232205367"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qWWYy82Onkdr",
    "colab_type": "code",
    "outputId": "1825ccc8-5fcf-4115-d1ff-9d45d8cc11bd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54434827053E12,
     "user_tz": -330.0,
     "elapsed": 728.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5482993197278911"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oFwBVtuti_Qi",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "bbae8259-108d-4b0e-ac4c-e7301ccf837c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348271822E12,
     "user_tz": -330.0,
     "elapsed": 1035.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(random_state=1)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Unm8wDJ6i_Us",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "90d5b600-8ad7-4405-da8e-bbd429f8a5eb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348278782E12,
     "user_tz": -330.0,
     "elapsed": 806.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859393232205367"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WynILdWIi_YR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "8cdcee0f-dc49-4294-d48c-8c2789599e44",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348279983E12,
     "user_tz": -330.0,
     "elapsed": 573.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5482993197278911"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EptMEXUqmdnr",
    "colab_type": "code",
    "outputId": "850500a4-5dd4-405a-a8f6-df5d9fa69156",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544348281259E12,
     "user_tz": -330.0,
     "elapsed": 1023.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=50,min_samples_split=4,)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BULtcik1pLVO",
    "colab_type": "code",
    "outputId": "62f2c0da-4854-4b39-934e-0bb70578f1b3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187584394E12,
     "user_tz": -330.0,
     "elapsed": 1529.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970828471411902"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4gJ6G4r3pLY_",
    "colab_type": "code",
    "outputId": "7d685af3-4442-466a-d716-a0e4c2f52ecc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.5441875888E12,
     "user_tz": -330.0,
     "elapsed": 1114.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6625850340136055"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "PuSzbz_njH0b",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "5b8eb98e-bfd1-4f01-c448-47eb131b1938",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251289301E12,
     "user_tz": -330.0,
     "elapsed": 1166.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=50,min_samples_split=4,)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "dhn8GMohjH7U",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "095ce2f8-1db4-4910-b387-94113f0d902d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251300346E12,
     "user_tz": -330.0,
     "elapsed": 1115.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658109684947491"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "tXoVfj_2jH_R",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "85bbb656-df66-489a-b784-5a97fcd736cf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251309729E12,
     "user_tz": -330.0,
     "elapsed": 1164.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5571428571428572"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "l7373VW6pLcs",
    "colab_type": "code",
    "outputId": "272b367b-fc94-4a05-a0db-8ffe20b7c87f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187592256E12,
     "user_tz": -330.0,
     "elapsed": 3001.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=300,min_samples_split=20,min_samples_leaf=4)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "omtnyPUxpLgK",
    "colab_type": "code",
    "outputId": "63ee5208-cc02-432d-b680-e0b85b8e370a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187681275E12,
     "user_tz": -330.0,
     "elapsed": 1488.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829638273045507"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mXod2SLopLld",
    "colab_type": "code",
    "outputId": "5d78c0b5-c131-4c1f-c12a-85359026843d",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187682921E12,
     "user_tz": -330.0,
     "elapsed": 1159.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170068027210884"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "AI6wsRz6jTNB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "13d66d18-03a5-4e31-a0ff-04ef62cca385",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251329894E12,
     "user_tz": -330.0,
     "elapsed": 2064.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=300,min_samples_split=20,min_samples_leaf=4)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "sXVeAmfJjTRJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "ddc57bf3-e123-46e4-a7f6-44afd3c02466",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251336676E12,
     "user_tz": -330.0,
     "elapsed": 1717.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6502333722287048"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "zakTYi65jTX8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "f1900ef7-1a99-4f30-b83d-edee46d1cbd7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251345793E12,
     "user_tz": -330.0,
     "elapsed": 1647.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5040816326530613"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Yke_DH69pLjn",
    "colab_type": "code",
    "outputId": "9809a4c7-9605-4e78-dd58-532bb14f7cb9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187686587E12,
     "user_tz": -330.0,
     "elapsed": 3094.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=300,min_samples_split=20,min_samples_leaf=6)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ynCPVc2_pa3k",
    "colab_type": "code",
    "outputId": "4336f712-cce1-4329-cd45-a1112ccd4b87",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187696662E12,
     "user_tz": -330.0,
     "elapsed": 1204.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7689614935822637"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "w-HrS7HPpa7E",
    "colab_type": "code",
    "outputId": "b9add71d-2147-489c-fdbd-9baf4d9663ef",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544187698003E12,
     "user_tz": -330.0,
     "elapsed": 1388.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608843537414966"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "QXjvaUCAjazB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "7556c3e9-b6e4-4d82-c029-b9a0f6806f2f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251360068E12,
     "user_tz": -330.0,
     "elapsed": 2127.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=1,n_estimators=300,min_samples_split=20,min_samples_leaf=6)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "2hclmtKGja2u",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "8a622330-0dad-40c8-83f1-237a55b052a3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251367795E12,
     "user_tz": -330.0,
     "elapsed": 1668.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6376896149358227"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gKHaexwLja6S",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "f6620832-583a-4533-9d99-c3a4ce6250b9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.544251376046E12,
     "user_tz": -330.0,
     "elapsed": 1171.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501360544217687"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "BdhO2lZTpa-X",
    "colab_type": "code",
    "outputId": "246a91e7-4bdc-46e7-b9db-1895ba455671",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32704.0
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1.544255752862E12,
     "user_tz": -330.0,
     "elapsed": 443492.0,
     "user": {
      "displayName": "Kavitha V",
      "photoUrl": "",
      "userId": "00448912820684317706"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1200 candidates, totalling 3600 fits\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200, total=   0.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200, total=   0.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300, total=   1.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300, total=   1.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=300, total=   1.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, total=   5.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, total=   5.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, total=   5.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000, total=  11.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000, total=  11.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=20, n_estimators=2000, total=  11.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000, total=  10.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000, total=  10.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=30, n_estimators=2000, total=  10.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000, total=   5.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000, total=   5.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=1000, total=   5.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000, total=  10.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000, total=  10.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=50, n_estimators=2000, total=  10.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=300, total=   1.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=1000, total=   4.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000, total=   9.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000, total=   9.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=100, n_estimators=2000, total=   9.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000, total=   9.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=3, min_samples_split=120, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=300, total=   1.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000, total=   5.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000, total=   5.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=1000, total=   5.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000, total=  11.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000, total=  10.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=20, n_estimators=2000, total=  10.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=1000, total=   5.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000, total=  10.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000, total=  10.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=30, n_estimators=2000, total=  10.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000, total=   4.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000, total=   4.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=1000, total=   4.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000, total=  10.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000, total=   9.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=50, n_estimators=2000, total=   9.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=1000, total=   4.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000, total=   9.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000, total=   9.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=100, n_estimators=2000, total=   9.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000, total=   4.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000, total=   9.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000, total=   9.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=4, min_samples_split=120, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=200, total=   1.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  5.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, total=   5.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, total=   5.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, total=   5.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000, total=  10.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000, total=  10.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=20, n_estimators=2000, total=  10.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=300, total=   1.6s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000, total=   5.1s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000, total=   5.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=1000, total=   5.2s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000, total=  10.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000, total=  10.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=200, total=   1.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=30, n_estimators=2000, total=  10.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=300, total=   1.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000, total=   4.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000, total=   4.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=1000, total=   4.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000, total=   9.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000, total=   9.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=100, total=   0.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=50, n_estimators=2000, total=   9.8s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000, total=   9.0s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=100, total=   0.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=200, total=   0.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=100, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300, total=   1.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300, total=   1.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=300, total=   1.3s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000, total=   4.4s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=1000, total=   4.5s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000, total=   8.9s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV] bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV] bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=3, min_samples_split=20, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=80, max_features=2, min_samples_leaf=5, min_samples_split=120, n_estimators=2000, total=   7.7s\n",
      "[CV] bootstrap=True, max_depth=80, max_features=3, min_samples_leaf=3, min_samples_split=20, n_estimators=200 \n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\", line 328, in fit\n    for i, t in enumerate(trees))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\", line 121, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\", line 790, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\", line 242, in fit\n    raise ValueError(\"max_features must be in (0, n_features]\")\nValueError: max_features must be in (0, n_features]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Dec  8 07:59:34 2018\nPID: 13736                                   Python 3.6.7: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=       density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], y=4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([1065, 1071, 1076, ..., 3425, 3426, 3427]), test=array([   0,    1,    2, ..., 1299, 1348, 1359]), verbose=2, parameters={'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       density  alcohol\n654   0.99170     11.4\n20...7\n235   0.99790      9.0\n\n[2282 rows x 2 columns]\n        y_train = 654     7\n2026    5\n981     7\n4657    7\n674     ...5     6\nName: quality, Length: 2282, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 99\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=867376502, splitter='best')>\n        X = array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32)\n        y = array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]])\n        sample_weight = None\n        curr_sample_weight = array([2., 1., 1., ..., 0., 1., 3.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    785 \n    786         super(DecisionTreeClassifier, self).fit(\n    787             X, y,\n    788             sample_weight=sample_weight,\n    789             check_input=check_input,\n--> 790             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    791         return self\n    792 \n    793     def predict_proba(self, X, check_input=True):\n    794         \"\"\"Predict class probabilities of the input samples X.\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Dec  8 07:59:34 2018\nPID: 13736                                   Python 3.6.7: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=       density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], y=4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([1065, 1071, 1076, ..., 3425, 3426, 3427]), test=array([   0,    1,    2, ..., 1299, 1348, 1359]), verbose=2, parameters={'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       density  alcohol\n654   0.99170     11.4\n20...7\n235   0.99790      9.0\n\n[2282 rows x 2 columns]\n        y_train = 654     7\n2026    5\n981     7\n4657    7\n674     ...5     6\nName: quality, Length: 2282, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 99\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=867376502, splitter='best')>\n        X = array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32)\n        y = array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]])\n        sample_weight = None\n        curr_sample_weight = array([2., 1., 1., ..., 0., 1., 3.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    785 \n    786         super(DecisionTreeClassifier, self).fit(\n    787             X, y,\n    788             sample_weight=sample_weight,\n    789             check_input=check_input,\n--> 790             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    791         return self\n    792 \n    793     def predict_proba(self, X, check_input=True):\n    794         \"\"\"Predict class probabilities of the input samples X.\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-bd472ff549b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7ffacfb024b0, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ffacfb024b0, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<google.colab._kernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 8, 7, 52, 16, 709057, tzinfo=tzlocal()), 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'session': '726e22d67a1a41b6eb697fdd031993dd', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': 'BdhO2lZTpa-X'}}, 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <google.colab._kernel.Kernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'726e22d67a1a41b6eb697fdd031993dd']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 8, 7, 52, 16, 709057, tzinfo=tzlocal()), 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'session': '726e22d67a1a41b6eb697fdd031993dd', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': 'BdhO2lZTpa-X'}}, 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in execute_request(self=<google.colab._kernel.Kernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'726e22d67a1a41b6eb697fdd031993dd'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', 'silent': False, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 8, 7, 52, 16, 709057, tzinfo=tzlocal()), 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'session': '726e22d67a1a41b6eb697fdd031993dd', 'username': 'username', 'version': '5.0'}, 'metadata': {'colab': {'cell_id': 'BdhO2lZTpa-X'}}, 'msg_id': '3c24667affd54393c2a462fa8823d120', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py in do_execute(self=<google.colab._kernel.Kernel object>, code='from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <google.colab._shell.Shell object>>\n        code = 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py in run_cell(self=<google.colab._shell.Shell object>, *args=('from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <google.colab._shell.Shell object>>\n        args = ('from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<google.colab._shell.Shell object>, raw_cell='from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<google.colab._shell.Shell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-62-bd472ff549b8>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7ffaa2cb3518, executi..._before_exec=None error_in_exec=None result=None>)\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n   2827                 code = compiler(mod, cell_name, \"single\")\n-> 2828                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <google.colab._shell.Shell object>>\n        code = <code object <module> at 0x7ffaa1c38c90, file \"<ipython-input-62-bd472ff549b8>\", line 12>\n        result = <ExecutionResult object at 7ffaa2cb3518, executi..._before_exec=None error_in_exec=None result=None>\n   2829                     return True\n   2830 \n   2831             # Flush softspace\n   2832             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_code(self=<google.colab._shell.Shell object>, code_obj=<code object <module> at 0x7ffaa1c38c90, file \"<ipython-input-62-bd472ff549b8>\", line 12>, result=<ExecutionResult object at 7ffaa2cb3518, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7ffaa1c38c90, file \"<ipython-input-62-bd472ff549b8>\", line 12>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', \"import numpy as np\\nimport pandas as pd\\nimport ma...chdir('/content/gdrive/My Drive/ML/wine dataset')\", \"get_ipython().magic('ls ')\", \"train=pd.read_csv('whitewine.csv')\", 'train', 'import copy\\ntrain1=train.copy()', 'train.describe()', 'train.info()', 'train.quantile(.75-.25)', 'train.std()', 'train.kurtosis()', 'train.skew()', 'train.var()', 'import seaborn as sns\\ntrain.plot.kde()', 'train.hist()', 'train.boxplot()', 'train.corr()', 'fig, ax = plt.subplots()\\nfig.set_size_inches(8, 4)\\n\\nax=sns.heatmap(train.corr())', \"y=train['quality']\", ...], 'Out': {5:       fixed acidity  volatile acidity  citric ac...7  11.800000        6  \n\n[4898 rows x 12 columns], 7:        fixed acidity  volatile acidity  citric a...3.820000     1.080000    14.200000     9.000000  , 9: fixed acidity             6.80000\nvolatile acidi...                6.00000\nName: 0.5, dtype: float64, 10: fixed acidity            0.843868\nvolatile acidi...\nquality                  0.885639\ndtype: float64, 11: fixed acidity            2.172178\nvolatile acidi...\nquality                  0.216526\ndtype: float64, 12: fixed acidity           0.647751\nvolatile acidit...2\nquality                 0.155796\ndtype: float64, 13: fixed acidity              0.712114\nvolatile aci...uality                    0.784356\ndtype: float64, 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: array([[<matplotlib.axes._subplots.AxesSubplot o... object at 0x7ffaa4d7d048>]],\n      dtype=object), 16: <matplotlib.axes._subplots.AxesSubplot object>, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 0.501360544217687, '_10': fixed acidity            0.843868\nvolatile acidi...\nquality                  0.885639\ndtype: float64, '_11': fixed acidity            2.172178\nvolatile acidi...\nquality                  0.216526\ndtype: float64, '_12': fixed acidity           0.647751\nvolatile acidit...2\nquality                 0.155796\ndtype: float64, '_13': fixed acidity              0.712114\nvolatile aci...uality                    0.784356\ndtype: float64, '_14': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.model_selection import GridSearchCV...bs=-1,verbose=2)\\ngrid_search.fit(x_train,y_train)', \"import numpy as np\\nimport pandas as pd\\nimport ma...chdir('/content/gdrive/My Drive/ML/wine dataset')\", \"get_ipython().magic('ls ')\", \"train=pd.read_csv('whitewine.csv')\", 'train', 'import copy\\ntrain1=train.copy()', 'train.describe()', 'train.info()', 'train.quantile(.75-.25)', 'train.std()', 'train.kurtosis()', 'train.skew()', 'train.var()', 'import seaborn as sns\\ntrain.plot.kde()', 'train.hist()', 'train.boxplot()', 'train.corr()', 'fig, ax = plt.subplots()\\nfig.set_size_inches(8, 4)\\n\\nax=sns.heatmap(train.corr())', \"y=train['quality']\", ...], 'Out': {5:       fixed acidity  volatile acidity  citric ac...7  11.800000        6  \n\n[4898 rows x 12 columns], 7:        fixed acidity  volatile acidity  citric a...3.820000     1.080000    14.200000     9.000000  , 9: fixed acidity             6.80000\nvolatile acidi...                6.00000\nName: 0.5, dtype: float64, 10: fixed acidity            0.843868\nvolatile acidi...\nquality                  0.885639\ndtype: float64, 11: fixed acidity            2.172178\nvolatile acidi...\nquality                  0.216526\ndtype: float64, 12: fixed acidity           0.647751\nvolatile acidit...2\nquality                 0.155796\ndtype: float64, 13: fixed acidity              0.712114\nvolatile aci...uality                    0.784356\ndtype: float64, 14: <matplotlib.axes._subplots.AxesSubplot object>, 15: array([[<matplotlib.axes._subplots.AxesSubplot o... object at 0x7ffaa4d7d048>]],\n      dtype=object), 16: <matplotlib.axes._subplots.AxesSubplot object>, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 0.501360544217687, '_10': fixed acidity            0.843868\nvolatile acidi...\nquality                  0.885639\ndtype: float64, '_11': fixed acidity            2.172178\nvolatile acidi...\nquality                  0.216526\ndtype: float64, '_12': fixed acidity           0.647751\nvolatile acidit...2\nquality                 0.155796\ndtype: float64, '_13': fixed acidity              0.712114\nvolatile aci...uality                    0.784356\ndtype: float64, '_14': <matplotlib.axes._subplots.AxesSubplot object>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/content/gdrive/My Drive/ML/wine dataset/<ipython-input-62-bd472ff549b8> in <module>()\n      7     'min_samples_split':[20,30,50,100,120],\n      8     'n_estimators':[100,200,300,1000,2000]\n      9 }\n     10 rf=RandomForestClassifier()\n     11 grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n---> 12 grid_search.fit(x_train,y_train)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=2), X=       density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], y=4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns]\n        y = 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Dec  8 07:59:34 2018\nPID: 13736                                   Python 3.6.7: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False),        density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], 4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, {'score': <function _passthrough_scorer>}, array([1065, 1071, 1076, ..., 3425, 3426, 3427]), array([   0,    1,    2, ..., 1299, 1348, 1359]), 2, {'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=       density  alcohol\n4554  0.989610    12.70\n...\n235   0.997900     9.00\n\n[3428 rows x 2 columns], y=4554    6\n3401    5\n3330    6\n4462    6\n3171    ...5     6\nName: quality, Length: 3428, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([1065, 1071, 1076, ..., 3425, 3426, 3427]), test=array([   0,    1,    2, ..., 1299, 1348, 1359]), verbose=2, parameters={'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train =       density  alcohol\n654   0.99170     11.4\n20...7\n235   0.99790      9.0\n\n[2282 rows x 2 columns]\n        y_train = 654     7\n2026    5\n981     7\n4657    7\n674     ...5     6\nName: quality, Length: 2282, dtype: int64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 99\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    116                 warnings.simplefilter('ignore', DeprecationWarning)\n    117                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n--> 121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=867376502, splitter='best')>\n        X = array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32)\n        y = array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]])\n        sample_weight = None\n        curr_sample_weight = array([2., 1., 1., ..., 0., 1., 3.])\n    122     else:\n    123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    124 \n    125     return tree\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    785 \n    786         super(DecisionTreeClassifier, self).fit(\n    787             X, y,\n    788             sample_weight=sample_weight,\n    789             check_input=check_input,\n--> 790             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    791         return self\n    792 \n    793     def predict_proba(self, X, check_input=True):\n    794         \"\"\"Predict class probabilities of the input samples X.\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=867376502, splitter='best'), X=array([[ 0.9917 , 11.4    ],\n       [ 0.9925 , 1...  ],\n       [ 0.9979 ,  9.     ]], dtype=float32), y=array([[4.],\n       [2.],\n       [4.],\n       ...,\n       [1.],\n       [2.],\n       [3.]]), sample_weight=array([2., 1., 1., ..., 0., 1., 3.]), check_input=False, X_idx_sorted=None)\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={\n",
    "    'bootstrap':[True],\n",
    "    'max_depth':[80,90,100,110],\n",
    "    'max_features':[2,3,4,5],\n",
    "    'min_samples_leaf':[3,4,5],\n",
    "    'min_samples_split':[20,30,50,100,120],\n",
    "    'n_estimators':[100,200,300,1000,2000]\n",
    "}\n",
    "rf=RandomForestClassifier()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gKlOX28kpg8p",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YBtmgZnMpg_3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Nty3gcgJphC_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "2XsHXsarphGa",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wLPIgrwUpbCD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "whitewine.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
